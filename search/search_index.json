{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#gpt-rag-solution-accelerator","title":"GPT-RAG Solution Accelerator","text":"<p>GPT-RAG is an enterprise-grade accelerator for building robust Retrieval-Augmented Generation (RAG) solutions on Azure. It provides a modular and secure foundation that integrates Azure OpenAI, AI Search, AI Foundry, and modern orchestration patterns to power intelligent assistants and data-driven applications across the enterprise.</p> <p>Designed with Zero-Trust security and Infrastructure as Code (IaC) principles from the ground up, GPT-RAG accelerates production deployments while ensuring consistency, governance, and operational excellence. It supports text, image, and voice scenarios, enabling organizations to rapidly create rich multimodal experiences.</p> <p>Latest Stable Release v2.2.5 </p> <p> Zero-Trust Architecture</p>"},{"location":"#core-services","title":"Core Services","text":"Services Description Orchestrator Manages multi-agent workflows and retrieves context using Semantic Kernel and Azure AI. Web UI User interface for chat interactions, supports streaming and custom themes. Data Ingestion Extracts, chunks, and indexes enterprise data for optimized retrieval. MCP Server Implements the Model Context Protocol for tool hosting and business logic integration."},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions from the community! Check our Contribution Guidelines for CLA, code of conduct, and PR guidelines.</p>"},{"location":"architecture/","title":"Overview","text":""},{"location":"architecture/#architecture","title":"\ud83c\udfdb\ufe0f Architecture","text":"<p>Download Visio Diagram</p>"},{"location":"architecture/#key-capabilities","title":"Key Capabilities","text":"<ul> <li> <p>Enterprise-Grade Security   Zero-Trust architecture with private endpoints, Azure Key Vault integration, and comprehensive monitoring.</p> </li> <li> <p>Flexible &amp; Customizable   Modular design with customizable orchestration, multiple interface options, and bring-your-own-resources support.</p> </li> <li> <p>Multimodal Experience   Native support for text, images, and voice with SharePoint and Fabric connectors for seamless data integration.</p> </li> <li> <p>Production Ready   Enterprise-ready infrastructure with support for CI/CD pipelines and quality evaluation integration.</p> </li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>We appreciate contributions and suggestions for this project!</p> <p>While anyone can submit pull requests at any time, we created a contributor form to help match volunteers with areas where we need the most help. It's optional but helps us better organize and direct contributions!</p>"},{"location":"contributing/#ways-to-contribute","title":"Ways to Contribute","text":"<ul> <li>Issues: Report bugs, propose enhancements, or share feature requests.</li> <li>Comments: Engage in discussions, help others, and review proposals.</li> <li>Documentation: Improve guides and clarity for new users.</li> <li>Design: Contribute to open design discussions and new patterns.</li> <li>Tests: Strengthen reliability through unit and integration tests.</li> <li>Code: Submit fixes, enhancements, or new modules via pull requests.</li> </ul>"},{"location":"contributing/#contribution-guidelines","title":"Contribution Guidelines","text":"<p>To maintain project quality, the following items will be considered during the PR review.</p> <p>Adhering to these best practices will streamline the review process.</p> <ul> <li> <p>Target the <code>develop</code> Branch: Always direct your pull request to the <code>develop</code> branch to ensure that changes are properly integrated into the project's development workflow.</p> </li> <li> <p>Keep Pull Requests Small: Aim to make your pull requests as focused and concise as possible. This makes it easier to review and ensures quicker integration into the codebase.</p> </li> <li> <p>Associate with Prioritized Issues: Ensure that each pull request is linked to a specific, prioritized issue in the project backlog. This helps maintain alignment with project goals and ensures that work is being done on tasks of the highest importance.</p> </li> <li> <p>Include Documentation: Every new feature or functionality must be accompanied by clear documentation explaining its purpose and configuration. This ensures others can use it independently in a self-service manner.</p> </li> <li> <p>Bugs and Documentation Corrections: Pull requests that address bugs or correct documentation do not need to be associated with prioritized issues. These can be submitted directly to maintain the quality and accuracy of the project.</p> </li> <li> <p>Multi-Repo Dependencies: If your pull request has dependencies on updates in other repositories, make sure to mention this in the pull request description. Additionally, create a corresponding pull request in the other repository to ensure synchronized updates across all related projects.</p> </li> </ul>"},{"location":"contributing/#code-update-workflow","title":"Code Update Workflow","text":"<p>We use a simplified version of the Fork and Branch Workflow alongside Git Flow for branching strategy. The <code>main</code> branch always contains deployment-ready code, while the <code>develop</code> branch serves as our integration branch.</p> <p>Contributors create feature branches from <code>develop</code> in their forks. Once changes are completed, they submit a pull request to the <code>develop</code> branch in the upstream repository. After review and approval, reviewers merge the changes into <code>develop</code>. Weekly, maintainers group these changes into a pull request from <code>develop</code> to <code>main</code> for final review and merging.</p>"},{"location":"contributing/#process-overview","title":"Process Overview","text":"<p>This section outlines the contribution process, highlighting the key actions for both contributors and maintainers. The accompanying diagram visually represents the workflow.</p> <p></p> <p>1) Fork the Repository</p> <p>Create a copy of the GPT-RAG upstream repository under your own GitHub account.</p> <p>2) Clone Locally</p> <p>Download your forked repository to your local machine.</p> <p>3) Add Upstream </p> <p>Link the original GPT-RAG upstream repository as <code>upstream</code> to keep your fork synchronized.</p> <p>4) Create a Feature Branch</p> <p>From your fork\u2019s <code>develop</code> branch, create a feature branch for your change (e.g., <code>feature/feature_x</code>).</p> <p>5) Commit and Push Changes</p> <p>Implement your updates locally, commit, and push them to your fork on GitHub.</p> <p>6) Open and Merge the Pull Request to <code>develop</code></p> <p>Open a PR from your feature branch in your fork to the upstream repository\u2019s <code>develop</code> branch.</p> <p>7) Sync with Upstream <code>develop</code></p> <p>After your PR is merged, update your fork's <code>develop</code> branch with the latest changes from the upstream.</p> <p>8) Create a Release Branch (Maintainers)</p> <p>When the <code>develop</code> branch is ready for release, create a branch named <code>release/x.y.z</code> from your fork's <code>develop</code>. This branch will be tested and validated before merging to <code>main</code>.</p> <p>9) Open a Pull Request to Upstream <code>main</code> (Maintainers)</p> <p>Once the release is validated, open a PR from your release branch to the upstream <code>main</code>. After the merge, maintainers will create a version tag (e.g., <code>v2.0.1</code>).</p> <p>10) Sync Your Fork</p> <p>Finally, update both your fork\u2019s <code>main</code> and <code>develop</code> branches to reflect the latest upstream state.</p>"},{"location":"contributing/#step-by-step","title":"Step-by-Step","text":"<p>Here\u2019s an example of implementing a feature called <code>conversation-metadata</code> in the <code>gpt-rag-orchestrator</code> repository.</p> <p>1) Create a Fork</p> <pre><code>https://github.com/placerda/gpt-rag-orchestrator.git\n</code></pre> <p>2) Clone Your Fork Locally</p> <pre><code>git clone https://github.com/placerda/gpt-rag-orchestrator.git\n</code></pre> <p>3) Set Upstream Remote</p> <pre><code>git remote add upstream git@github.com:Azure/gpt-rag-orchestrator.git\n</code></pre> <p>4) Create a Feature Branch</p> <pre><code>git checkout -b feature/conversation-metadata develop\n</code></pre> <p>5) Make and Push Your Changes</p> <pre><code>git add .\ngit commit -m \"Implemented conversation metadata\"\ngit push origin feature/conversation-metadata\n</code></pre> <p>6) Open and Merge the Pull Request to <code>develop</code></p> <ul> <li>6a. Create the PR:      Go to your fork on GitHub \u2192 click New Pull Request \u2192      Base: <code>Azure/gpt-rag-orchestrator</code> \u2192 <code>develop</code>      Compare: <code>placerda/gpt-rag-orchestrator</code> \u2192 <code>feature/conversation-metadata</code></li> <li>6b. Maintainer Review:      The maintainers will review, request changes if needed, and merge the PR into the upstream <code>develop</code>.</li> </ul> <p>7) Sync Your Fork\u2019s <code>develop</code></p> <pre><code>git fetch upstream\ngit checkout develop\ngit merge upstream/develop\ngit push origin develop\n</code></pre> <p>8) Create a Release Branch (Maintainers)</p> <pre><code>git checkout -b release/2.0.1 develop\ngit push origin release/2.0.1\n</code></pre> <p>9) Open a Pull Request to Upstream <code>main</code> (Maintainers)</p> <ul> <li>Base: <code>Azure/gpt-rag-orchestrator</code> \u2192 <code>main</code></li> <li>Compare: <code>placerda/gpt-rag-orchestrator</code> \u2192 <code>release/2.0.1</code></li> <li>After review and merge, maintainers tag the release (e.g., <code>v2.0.1</code>).</li> </ul> <p>10) Sync Your Fork After Tag Creation</p> <pre><code>git fetch upstream\ngit checkout main\ngit merge upstream/main\ngit push origin main\n</code></pre>"},{"location":"contributing/#legal-and-code-of-conduct","title":"Legal and Code of Conduct","text":"<p>Before contributing, you'll need to sign a Contributor License Agreement (CLA) to confirm that you have the rights to, and do, grant us permission to use your contribution. More details can be found at Microsoft CLA.</p> <p>This project adheres to the Microsoft Open Source Code of Conduct. For more information, please visit the Code of Conduct FAQ or contact opencode@microsoft.com with any questions or comments.</p>"},{"location":"deploy/","title":"\ud83d\ude80 Deployment Guide","text":"<p>Choose your preferred deployment method based on project requirements and environment constraints.</p> <p>Note: You can change parameter values in <code>main.parameters.json</code> or set them with <code>azd env set</code> before running <code>azd provision</code>. This applies only to parameters that support environment variable substitution.</p>"},{"location":"deploy/#prerequisites","title":"Prerequisites","text":"<p>Required Permissions:</p> <ul> <li>Azure subscription with Contributor and User Access Admin roles</li> <li>Agreement to Responsible AI terms for Azure AI Services</li> </ul> <p>Required Tools:</p> <ul> <li>Azure Developer CLI</li> <li>PowerShell 7+ (Windows only)</li> <li>Git</li> <li>Python 3.12</li> </ul>"},{"location":"deploy/#quick-start-basic-deployment","title":"Quick Start - Basic Deployment","text":"<p>Quick setup for demos without network isolation.</p> <pre><code>azd init -t azure/gpt-rag\naz login\nazd auth login\nazd provision\n</code></pre> <p>Add <code>--tenant</code> for <code>az</code> or <code>--tenant-id</code> for <code>azd</code> if you want a specific tenant.</p> <p>Demo video:</p>"},{"location":"deploy/#zero-trust-deployment","title":"Zero Trust Deployment","text":"<p>For deployments that require network isolation.</p>"},{"location":"deploy/#before-provisioning","title":"Before Provisioning","text":"<p>Enable network isolation in your environment:</p> <pre><code>azd env set NETWORK_ISOLATION true\n</code></pre> <p>Make sure you\u2019re signed in with your Azure user account:</p> <pre><code>az login\nazd auth login\n</code></pre> <p>Add <code>--tenant</code> for <code>az</code> or <code>--tenant-id</code> for <code>azd</code> if you want a specific tenant.</p>"},{"location":"deploy/#provision-infrastructure","title":"Provision Infrastructure","text":"<pre><code>azd provision\n</code></pre>"},{"location":"deploy/#post-provision-configuration","title":"Post-Provision Configuration","text":"<p>The Bicep template provisions a Jumpbox VM by default. You can connect to it to perform the post-provision steps, deploy services, and run tests.</p> <p>Option A \u2013 Using the deployed Jumpbox VM</p> <p>Reset the VM password in the Azure Portal (required on first access if not set in deployment parameters): Go to your VM resource \u2192 Support + troubleshooting \u2192 Reset password \u2192 Set new credentials.</p> <p>Note: default username is <code>testvmuser</code></p> <p>Connect via Azure Bastion.</p> <p>Once connected, authenticate with the VM\u2019s Managed Identity:</p> <pre><code>az login --identity\nazd auth login --with-managed-identity\n</code></pre> <p>Add <code>--tenant</code> for <code>az</code> or <code>--tenant-id</code> for <code>azd</code> if you want a specific tenant.</p> <p>Open a terminal in the VM and run:</p> <pre><code>cd c:\\github\\gpt-rag\n.\\scripts\\postProvision.ps1\n</code></pre> <p>Option B \u2013 From your local machine (must have VNet access)</p> <p>From the <code>gpt-rag</code> directory, run:</p> <pre><code>.\\scripts\\postProvision.ps1\n</code></pre> <p>or (Bash)</p> <pre><code>.\\scripts\\postProvision.sh\n</code></pre> <p>Note: If you have re-initialized or cloned the gpt-rag repo again, refresh your <code>azd</code> environment before running postProvision script so it points to the existing deployment: <code>azd init -t azure/gpt-rag</code> then <code>azd env refresh</code>. When prompted, select the same Subscription, Resource Group, and Location as the original provisioning so <code>azd</code> correctly links to your environment.</p>"},{"location":"deploy/#deploy-gpt-rag-services","title":"Deploy GPT-RAG Services","text":"<p>Once the GPT-RAG infrastructure is provisioned, you can deploy the services.</p> <p>To deploy all services at once, navigate to the <code>gpt-rag</code> directory (with azd environment configured) and run:</p> <pre><code>azd deploy\n</code></pre> <p>This command deploys each service in sequence.</p> <p>If you prefer to deploy a single service\u2014for example, when updating only that service\u2014navigate to the corresponding service repository and follow the instructions in its \"How to Deploy\" section.</p>"},{"location":"deploy/#permissions","title":"Permissions","text":"<p>AI Foundry Role and AI Search Assignments</p> Resource Role Assignee Description GenAI App Search Service Search Index Data Reader AI Foundry Project Read index data GenAI App Search Service Search Service Contributor AI Foundry Project Create AI search connection GenAI App Storage Account Storage Blob Data Reader AI Foundry Account Read blob data GenAI App Storage Account Storage Blob Data Reader Search Service Read blob data for search integration AI Foundry Storage Account Storage Blob Data Contributor AI Foundry Project Enable agent to store/retrieve blob artifacts in customer storage AI Foundry Storage Account Containers Storage Blob Data Owner (workspace) AI Foundry Project Scoped owner access to workspace containers for session-specific data AI Foundry Cosmos DB Account Cosmos DB Operator AI Foundry Project Control-plane operations for enterprise memory database (threads) AI Foundry Cosmos DB Containers Cosmos DB Built-in Data Contributor AI Foundry Project Read/write conversation threads within enterprise memory containers AI Foundry Search Service Search Service Contributor AI Foundry Project Create/update indexes for vector search workflows AI Foundry Search Service Search Index Data Contributor AI Foundry Project Read/write index data for embedding-based queries <p>Container App Role Assignments</p> Resource Role Assignee Description GenAI App Configuration Store App Configuration Data Reader ContainerApp: orchestrator Read configuration data GenAI App Configuration Store App Configuration Data Reader ContainerApp: frontend Read configuration data GenAI App Configuration Store App Configuration Data Reader ContainerApp: dataingest Read configuration data GenAI App Configuration Store App Configuration Data Reader ContainerApp: mcp Read configuration data GenAI App Container Registry AcrPull ContainerApp: mcp Pull container images GenAI App Container Registry AcrPull ContainerApp: orchestrator Pull container images GenAI App Container Registry AcrPull ContainerApp: frontend Pull container images GenAI App Container Registry AcrPull ContainerApp: dataingest Pull container images GenAI App Key Vault Key Vault Secrets User ContainerApp: orchestrator Read secrets GenAI App Key Vault Key Vault Secrets User ContainerApp: frontend Read secrets GenAI App Key Vault Key Vault Secrets User ContainerApp: dataingest Read secrets GenAI App Key Vault Key Vault Secrets User ContainerApp: mcp Read secrets GenAI App Search Service Search Index Data Reader ContainerApp: orchestrator Read index data GenAI App Search Service Search Index Data Contributor ContainerApp: dataingest Read/write index data GenAI App Search Service Search Index Data Contributor ContainerApp: mcp Read/write index data GenAI App Storage Account Storage Blob Data Reader ContainerApp: orchestrator Read blob data GenAI App Storage Account Storage Blob Data Reader ContainerApp: frontend Read blob data GenAI App Storage Account Storage Blob Data Contributor ContainerApp: dataingest Read/write blob data GenAI App Storage Account Storage Blob Data Contributor ContainerApp: mcp Read/write blob data GenAI App Storage Account Storage Queue Data Contributor ContainerApp: mcp Read/write storage queue data GenAI App Cosmos DB Cosmos DB Built-in Data Contributor ContainerApp: orchestrator Read/write Cosmos DB data AI Foundry Account Cognitive Services User ContainerApp: orchestrator Access Cognitive Services operations AI Foundry Account Cognitive Services User ContainerApp: dataingest Access Cognitive Services operations AI Foundry Account Cognitive Services OpenAI User ContainerApp: orchestrator Use OpenAI APIs AI Foundry Account Cognitive Services OpenAI User ContainerApp: dataingest Use OpenAI APIs AI Foundry Account Cognitive Services User ContainerApp: mcp Access Cognitive Services AI Foundry Account Cognitive Services OpenAI User ContainerApp: mcp Use OpenAI APIs <p>Executor Role Assignments</p> Resource Role Assignee Description GenAI App Configuration Store App Configuration Data Owner Executor Full control over configuration settings GenAI App Container Registry AcrPush Executor Push container images GenAI App Key Vault Key Vault Contributor Executor Manage Key Vault settings GenAI App Key Vault Key Vault Secrets Officer Executor Create Key Vault secrets GenAI App Search Service Search Service Contributor Executor Create/update search service elements GenAI App Search Service Search Index Data Contributor Executor Read/write search index data GenAI App Storage Account Storage Blob Data Contributor Executor Read/write blob data GenAI App Cosmos DB Cosmos DB Built-in Data Contributor Executor Read/write Cosmos DB data AI Foundry Project Azure AI Project Manager Executor Manage AI Foundry projects and assign roles <p>Jumpbox VM Role Assignments</p> Resource Role Assignee Description GenAI App Container Apps Container Apps Contributor Jumpbox VM Full control over Container Apps (deploy/manage apps) Azure Managed Identity Managed Identity Operator Jumpbox VM Assign and manage user-assigned managed identities GenAI App Container Registry Container Registry Repository Writer Jumpbox VM Write to specific repositories GenAI App Container Registry Container Registry Tasks Contributor Jumpbox VM Manage ACR tasks GenAI App Container Registry Container Registry Data Access Configuration Administrator Jumpbox VM Manage data access configuration for ACR GenAI App Container Registry AcrPush Jumpbox VM Push container images GenAI App Configuration Store App Configuration Data Owner Jumpbox VM Full control over configuration settings GenAI App Key Vault Key Vault Contributor Jumpbox VM Manage Key Vault settings GenAI App Key Vault Key Vault Secrets Officer Jumpbox VM Create Key Vault secrets GenAI App Search Service Search Service Contributor Jumpbox VM Create/update search service elements GenAI App Search Service Search Index Data Contributor Jumpbox VM Read/write search index data GenAI App Storage Account Storage Blob Data Contributor Jumpbox VM Read/write blob data AI Foundry Account Azure AI Project Manager Jumpbox VM Manage AI Foundry projects and assign roles AI Foundry Account Cognitive Services Contributor Jumpbox VM Manage Cognitive Services resources GenAI App Cosmos DB Cosmos DB Built-in Data Contributor Jumpbox VM Read/write Cosmos DB data"},{"location":"nl2sql-quickstart/","title":"NL2SQL Quick Start Guide","text":"<p>Get public access natural language querying of your Azure SQL Database working in 30 minutes using automated blob storage ingestion.</p> <p>This quickstart enables a public access solution which is for testing purposes only!</p>"},{"location":"nl2sql-quickstart/#prerequisites","title":"Prerequisites","text":"<p>You must have: - GPT-RAG solution deployed (<code>azd provision</code> and <code>azd deploy</code> completed) - Azure subscription with permissions to create SQL resources - Access to Azure Portal</p>"},{"location":"nl2sql-quickstart/#what-youll-accomplish","title":"What You'll Accomplish","text":"<p>By the end of this guide: - Create Azure SQL Database with AdventureWorksLT sample data - Configure networking and firewall rules - Store database credentials securely in Key Vault - Register your SQL database as a datasource - Upload table metadata and example queries to blob storage - Enable automated ingestion with CRON scheduling - Enable NL2SQL strategy - Ask questions in natural language and get SQL results</p>"},{"location":"nl2sql-quickstart/#step-1-create-azure-sql-database-5-10-min","title":"Step 1: Create Azure SQL Database (5-10 min)","text":""},{"location":"nl2sql-quickstart/#a-create-sql-server","title":"A. Create SQL Server","text":"<p>Azure Portal \u2192 Create a resource \u2192 SQL Database</p> <ol> <li>Basics tab:</li> <li>Subscription: Your subscription</li> <li>Resource group: Same as your GPT-RAG deployment (or create new)</li> <li>Database name: <code>adventureworks-demo</code></li> <li> <p>Server: Click Create new</p> </li> <li> <p>Create SQL Database Server:</p> </li> <li>Server name: <code>sql-gptrag-demo-&lt;unique&gt;</code> (must be globally unique)</li> <li>Location: Same region as GPT-RAG (optional - any region works, but same region reduces latency)</li> <li>Authentication method: Use SQL authentication (simpler for this quickstart; Entra ID authentication is also supported)</li> <li>Server admin login: <code>sqladmin</code></li> <li>Password: Create a strong password (save this!)</li> <li> <p>Click OK</p> </li> <li> <p>Compute + storage:</p> </li> <li>Click Configure database</li> <li>Select Basic (cheapest for testing - $5/month)</li> <li> <p>Click Apply</p> </li> <li> <p>Backup storage redundancy:</p> </li> <li>Select Locally-redundant backup storage (cheapest)</li> </ol>"},{"location":"nl2sql-quickstart/#b-configure-networking","title":"B. Configure Networking","text":"<ol> <li>Networking tab:</li> <li>Connectivity method: Public endpoint</li> <li>Firewall rules:<ul> <li>Allow Azure services and resources to access this server - YES (CRITICAL!)</li> <li>Add current client IP address - YES (for your testing)</li> </ul> </li> <li>Connection policy: Default</li> <li>Encrypted connections: TLS 1.2 (default)</li> </ol>"},{"location":"nl2sql-quickstart/#c-add-sample-data","title":"C. Add Sample Data","text":"<ol> <li>Additional settings tab:</li> <li>Use existing data: Sample (AdventureWorksLT)</li> <li>Collation: Default</li> <li> <p>Enable Microsoft Defender: Not needed for demo</p> </li> <li> <p>Click Review + create \u2192 Create</p> </li> </ol> <p>\u23f3 Wait 3-5 minutes for deployment to complete.</p>"},{"location":"nl2sql-quickstart/#d-verify-firewall-configuration-post-deployment","title":"D. Verify Firewall Configuration (Post-Deployment)","text":"<p>After deployment completes:</p> <p>\u26a0\ufe0f Important: Go to the SQL Server resource (not the database):</p> <p>Azure Portal \u2192 SQL servers \u2192 <code>sql-gptrag-demo-&lt;unique&gt;</code> \u2192 Security \u2192 Networking</p> <p>(Note: SQL databases \u2192 adventureworks-demo - that's the wrong place!)</p> <p>Verify these settings: - Public network access: Selected networks - Exceptions: \u2611\ufe0f Allow Azure services and resources to access this server (checked)</p> <p>The \"Allow Azure services\" checkbox creates a special firewall rule (<code>0.0.0.0 - 0.0.0.0</code>) that permits any Azure service in your subscription to connect.</p>"},{"location":"nl2sql-quickstart/#e-test-connection","title":"E. Test Connection","text":"<p>Using Azure Portal Query Editor:</p> <ol> <li>Go to your SQL Database \u2192 Query editor</li> <li>Login with SQL authentication (sqladmin / your password)</li> <li>Run test query:</li> </ol> <pre><code>SELECT TOP 5 ProductID, Name, ListPrice \nFROM SalesLT.Product \nORDER BY ListPrice DESC\n</code></pre> <p>If you see results, your database is ready!</p>"},{"location":"nl2sql-quickstart/#f-gather-connection-info","title":"F. Gather Connection Info","text":"<p>Save these details (you'll need them later):</p> <pre><code>Server: &lt;your-sql-server-name&gt;.database.windows.net\nDatabase: adventureworks-demo\nUsername: sqladmin\nPassword: &lt;your-password&gt;\n</code></pre>"},{"location":"nl2sql-quickstart/#step-2-find-your-gpt-rag-resources-3-min","title":"Step 2: Find Your GPT-RAG Resources (3 min)","text":"<p>Locate these in your resource group (they have your deployment suffix):</p> <pre><code>Key Vault: kv-&lt;suffix&gt;\nCosmos DB: cosmos-&lt;suffix&gt;\nAI Search: srch-&lt;suffix&gt;\nApp Config: appcs-&lt;suffix&gt;\nStorage Account: st&lt;suffix&gt; (note: no dash in storage account names)\n</code></pre> <p>Quick way to find suffix: <pre><code># List resource groups\naz group list --query \"[?contains(name,'gpt-rag')].name\" -o table\n\n# List resources in your group\naz resource list -g &lt;your-rg&gt; --query \"[].name\" -o table\n</code></pre></p>"},{"location":"nl2sql-quickstart/#step-3-store-password-in-key-vault-3-min","title":"Step 3: Store Password in Key Vault (3 min)","text":"<p>CRITICAL: Secret name MUST be <code>{datasource-id}-secret</code></p> <pre><code># Using the password you created in Step 1\n# If your datasource id will be \"adventureworks\"\n# Then secret name must be \"adventureworks-secret\"\n\naz keyvault secret set `\n  --vault-name \"kv-&lt;your-suffix&gt;\" `\n  --name \"adventureworks-secret\" `\n  --value \"&lt;your-sql-password-from-step-1&gt;\"\n</code></pre> <p>Verify it worked: <pre><code>az keyvault secret show `\n  --vault-name \"kv-&lt;your-suffix&gt;\" `\n  --name \"adventureworks-secret\" `\n  --query \"value\" -o tsv\n</code></pre></p>"},{"location":"nl2sql-quickstart/#step-4-grant-container-app-access-to-key-vault-2-min","title":"Step 4: Grant Container App Access to Key Vault (2 min)","text":"<pre><code># Get orchestrator's managed identity\n$principalId = az containerapp show `\n  --name \"ca-&lt;your-suffix&gt;-orchestrator\" `\n  --resource-group &lt;your-rg&gt; `\n  --query \"identity.principalId\" -o tsv\n\n# Grant access\naz role assignment create `\n  --assignee $principalId `\n  --role \"Key Vault Secrets User\" `\n  --scope \"/subscriptions/&lt;sub-id&gt;/resourceGroups/&lt;rg&gt;/providers/Microsoft.KeyVault/vaults/kv-&lt;your-suffix&gt;\"\n</code></pre>"},{"location":"nl2sql-quickstart/#step-5-register-database-in-cosmos-db-3-min","title":"Step 5: Register Database in Cosmos DB (3 min)","text":"<p>Azure Portal \u2192 Cosmos DB \u2192 cosmos-<code>&lt;suffix&gt;</code> \u2192 Data Explorer \u2192 ragdata database \u2192 datasources container \u2192 New Item</p> <p>Paste this JSON, replacing <code>&lt;your-sql-server-name&gt;</code> with the server name you created in Step 1 (e.g., <code>sql-gptrag-demo-xyz123</code>):</p> <pre><code>{\n    \"id\": \"adventureworks\",\n    \"type\": \"sql_database\",\n    \"description\": \"AdventureWorksLT sample database with products and customers\",\n    \"server\": \"&lt;your-sql-server-name&gt;.database.windows.net\",\n    \"database\": \"adventureworks-demo\",\n    \"uid\": \"sqladmin\",\n    \"metadata\": {\n        \"created_date\": \"2025-11-17\"\n    }\n}\n</code></pre> <p>\ud83d\udca1 How to find your server name: - Azure Portal \u2192 SQL servers \u2192 Look for the server you just created - Copy the name (e.g., <code>sql-gptrag-demo-ragpace</code>) - Add <code>.database.windows.net</code> to the end</p> <p>\u26a0\ufe0f CRITICAL RULES: - Use <code>uid</code> (NOT <code>username</code>) - DO NOT include <code>password</code> field - DO NOT include <code>connection_info</code> field - The <code>id</code> must match Key Vault secret prefix (<code>adventureworks</code> \u2192 <code>adventureworks-secret</code>)</p> <p>Click Save.</p>"},{"location":"nl2sql-quickstart/#step-6-create-metadata-json-files-5-min","title":"Step 6: Create Metadata JSON Files (5 min)","text":"<p>What you'll do in this step: - Create JSON files on your local machine (in your working directory) - These files describe your database tables and example queries - In Step 7, you'll upload these files to Azure Blob Storage - The automated ingestion system will then index them into AI Search</p>"},{"location":"nl2sql-quickstart/#a-create-local-folder-structure","title":"A. Create Local Folder Structure","text":"<p>On your local machine, create folders to organize the metadata files:</p> <pre><code>mkdir blob-upload\nmkdir blob-upload\\queries\nmkdir blob-upload\\tables\n</code></pre>"},{"location":"nl2sql-quickstart/#b-create-example-query-files","title":"B. Create Example Query Files","text":"<p>Why example queries? They help the AI understand your database patterns and generate better SQL. The system uses these as few-shot examples when translating natural language to SQL.</p> <p>\ud83d\udcdd Note: We're only adding 3 queries here for quick setup. Ideally, add 10-20 diverse examples covering: - Simple queries (counts, filters) - Complex joins across multiple tables - Aggregations (SUM, AVG, GROUP BY) - Date/time filtering - Common business questions your users ask</p> <p>More examples = better SQL generation accuracy!</p> <p>Create these files on your local machine:</p> <p>Create <code>blob-upload\\queries\\how_many_products.json</code>: <pre><code>{\n    \"question\": \"How many products are in the database?\",\n    \"query\": \"SELECT COUNT(*) as product_count FROM SalesLT.Product\",\n    \"reasoning\": \"Simple count of all products\",\n    \"datasource\": \"adventureworks\"\n}\n</code></pre></p> <p>Create <code>blob-upload\\queries\\top_expensive_products.json</code>: <pre><code>{\n    \"question\": \"Show me the top 5 most expensive products\",\n    \"query\": \"SELECT TOP 5 ProductID, Name, ListPrice FROM SalesLT.Product ORDER BY ListPrice DESC\",\n    \"reasoning\": \"Get highest priced products\",\n    \"datasource\": \"adventureworks\"\n}\n</code></pre></p> <p>Create <code>blob-upload\\queries\\product_categories.json</code>: <pre><code>{\n    \"question\": \"What product categories exist?\",\n    \"query\": \"SELECT DISTINCT Name FROM SalesLT.ProductCategory ORDER BY Name\",\n    \"reasoning\": \"List all unique categories\",\n    \"datasource\": \"adventureworks\"\n}\n</code></pre></p>"},{"location":"nl2sql-quickstart/#c-create-table-metadata-files","title":"C. Create Table Metadata Files","text":"<p>Why table metadata? </p> <p>The system uses AI Search for semantic table discovery instead of live database introspection. When users ask questions, the system: 1. Searches your table metadata using embeddings (vector search) 2. Finds the most relevant tables based on descriptions 3. Then calls <code>GetSchemaInfo</code> to retrieve detailed column information</p> <p>Benefits of this approach: - Fast semantic search - Find relevant tables using natural language (\"revenue data\" matches \"SalesOrderHeader\") - Control what's exposed - Only include tables relevant to end users (exclude admin/audit tables) - Add business context - Descriptions help the AI understand table purpose beyond raw schema - Avoid token limits - Don't send 500 table schemas to GPT-4 every query</p> <p>\u26a0\ufe0f Schema updates: - If you add/drop columns or tables later, create new JSON files and upload them - The automated ingestion will detect changes and re-index automatically</p> <p>Note</p> <p>Column descriptions are not specified here because the column names are sufficiently descriptive for the LLM</p> <p>Create these files on your local machine:</p> <p>Create <code>blob-upload\\tables\\saleslt_product.json</code>: <pre><code>{\n    \"table\": \"SalesLT.Product\",\n    \"description\": \"Product catalog with names, prices, and descriptions\",\n    \"datasource\": \"adventureworks\"\n}\n</code></pre></p> <p>Create <code>blob-upload\\tables\\saleslt_productcategory.json</code>: <pre><code>{\n    \"table\": \"SalesLT.ProductCategory\",\n    \"description\": \"Product categories for organizing products\",\n    \"datasource\": \"adventureworks\"\n}\n</code></pre></p> <p>Create <code>blob-upload\\tables\\saleslt_customer.json</code>: <pre><code>{\n    \"table\": \"SalesLT.Customer\",\n    \"description\": \"Customer information including names and contact details\",\n    \"datasource\": \"adventureworks\"\n}\n</code></pre></p>"},{"location":"nl2sql-quickstart/#step-7-upload-files-to-blob-storage-3-min","title":"Step 7: Upload Files to Blob Storage (3 min)","text":"<p>What this step does: - Uploads the local JSON files you created in Step 6 to Azure Blob Storage - Files go into the <code>nl2sql</code> container (this container already exists from your deployment) - The folder structure (<code>queries/</code> and <code>tables/</code>) will be created automatically during upload</p> <p>Upload command:</p> <pre><code># Upload all files (queries and tables)\naz storage blob upload-batch `\n  --account-name \"st&lt;your-suffix&gt;\" `\n  --destination nl2sql `\n  --source blob-upload `\n  --auth-mode login\n</code></pre> <p>Verify uploads: <pre><code># List all blobs in nl2sql container\naz storage blob list `\n  --account-name \"st&lt;your-suffix&gt;\" `\n  --container-name nl2sql `\n  --auth-mode login `\n  --query \"[].name\" -o table\n</code></pre></p> <p>You should see: <pre><code>queries/how_many_products.json\nqueries/top_expensive_products.json\nqueries/product_categories.json\ntables/saleslt_product.json\ntables/saleslt_productcategory.json\ntables/saleslt_customer.json\n</code></pre></p>"},{"location":"nl2sql-quickstart/#step-8-enable-automated-ingestion-3-min","title":"Step 8: Enable Automated Ingestion (3 min)","text":"<p>Azure Portal \u2192 App Configuration \u2192 appcs-<code>&lt;suffix&gt;</code> \u2192 Configuration explorer</p> <p>Click + Create to add a new key-value:</p> <p>Key: <code>CRON_RUN_NL2SQL_INDEX</code> Value: <code>*/15 * * * *</code> Label: <code>gpt-rag-ingestion</code> Content type: <code>text/plain</code></p> <p>Click Apply.</p> <p>What this does: - Runs the NL2SQL indexer job every 15 minutes - Scans the <code>nl2sql</code> container for new/changed files - Automatically indexes them into AI Search - Generates embeddings for semantic search - Skips unchanged files (smart change detection)</p> <p>Alternative schedules: - <code>*/5 * * * *</code> - Every 5 minutes (faster updates) - <code>*/2 * * * *</code> - Every 2 minutes (testing/development only) - <code>0 * * * *</code> - Every hour on the hour - <code>0 0 * * *</code> - Once daily at midnight</p> <p>Cost considerations: - CRON schedules are free - they're just timers, not separate compute - The Container App runs 24/7 regardless of schedule (~$30-50/month) - Each run generates embeddings via Azure OpenAI (~$0.001 per run) - Smart change detection skips unchanged files (saves costs) - Recommended for production: <code>*/15 * * * *</code> balances responsiveness with costs (~$3-5/month in embeddings) - For testing: Use <code>*/2 * * * *</code> to see results faster, then change to <code>*/15 * * * *</code></p>"},{"location":"nl2sql-quickstart/#step-9-enable-nl2sql-strategy-2-min","title":"Step 9: Enable NL2SQL Strategy (2 min)","text":"<p>Azure Portal \u2192 App Configuration \u2192 appcs-<code>&lt;suffix&gt;</code> \u2192 Configuration explorer</p> <ol> <li>Search for key: <code>AGENT_STRATEGY</code></li> <li>Click the key \u2192 Click Edit</li> <li>Change value to: <code>nl2sql</code></li> <li>Click Apply</li> </ol>"},{"location":"nl2sql-quickstart/#step-10-wait-for-initial-ingestion-2-3-min","title":"Step 10: Wait for Initial Ingestion (2-3 min)","text":"<p>The data ingestion Container App runs the indexer job: - On startup (happens once when container starts) - Every 15 minutes (based on CRON schedule)</p> <p>Option 1: Wait for next CRON run (up to 15 minutes, or 2 minutes if you used <code>*/2 * * * *</code> for testing)</p> <p>How it works: - The Container App runs the indexer on startup (immediate first run) - Then runs on the CRON schedule you configured - CRON runs at the next matching time (e.g., if schedule is <code>*/15 * * * *</code>, next run is at :00, :15, :30, or :45)</p> <p>Option 2: Force immediate ingestion by restarting the container:</p> <pre><code>az containerapp revision restart `\n  --name \"ca-&lt;your-suffix&gt;-dataingest\" `\n  --resource-group &lt;your-rg&gt; `\n  --revision $(az containerapp revision list --name \"ca-&lt;your-suffix&gt;-dataingest\" --resource-group &lt;your-rg&gt; --query \"[0].name\" -o tsv)\n</code></pre> <p>Verify indexing completed:</p> <p>Check the logs in blob storage: <pre><code># List ingestion run logs\naz storage blob list `\n  --account-name \"st&lt;your-suffix&gt;\" `\n  --container-name jobs `\n  --prefix \"nl2sql-indexer/runs/\" `\n  --auth-mode login `\n  --query \"[].{name:name, modified:properties.lastModified}\" -o table\n</code></pre></p> <p>Download the most recent log: <pre><code># Get the latest run log\n$latestLog = az storage blob list `\n  --account-name \"st&lt;your-suffix&gt;\" `\n  --container-name jobs `\n  --prefix \"nl2sql-indexer/runs/\" `\n  --auth-mode login `\n  --query \"[-1].name\" -o tsv\n\n# Download and view it\naz storage blob download `\n  --account-name \"st&lt;your-suffix&gt;\" `\n  --container-name jobs `\n  --name $latestLog `\n  --file run-log.json `\n  --auth-mode login\n\nGet-Content run-log.json | ConvertFrom-Json | ConvertTo-Json -Depth 10\n</code></pre></p> <p>Look for: - <code>\"success\": 3</code> (for queries) - <code>\"success\": 3</code> (for tables) - <code>\"failed\": 0</code> - <code>\"skipped\": 0</code> (first run - nothing skipped yet) - <code>\"vectorsGenerated\": 6</code> (embeddings created)</p> <p>On subsequent runs: - Files with no changes will show <code>\"skipped\": 6</code> and <code>\"candidates\": 0</code> - Only new or modified files will be re-indexed - This smart change detection saves costs and time</p>"},{"location":"nl2sql-quickstart/#step-11-test-it-2-min","title":"Step 11: Test It! (2 min)","text":"<p>Navigate to your UI: <code>https://ca-&lt;suffix&gt;-frontend.livelyglacier-&lt;random&gt;.eastus2.azurecontainerapps.io</code></p> <p>Try these questions: 1. \"How many products are in the database?\" 2. \"Show me the top 5 most expensive products\" 3. \"What product categories exist?\"</p> <p>Expected response: - Natural language answer with data - Shows SQL query that was executed - Cites the datasource</p>"},{"location":"nl2sql-quickstart/#what-you-just-enabled","title":"What You Just Enabled \ud83e\ude84","text":"<p>Congratulations! You've set up an automated NL2SQL ingestion pipeline. Your system now:</p>"},{"location":"nl2sql-quickstart/#automated-metadata-management","title":"\ud83e\udde0 Automated Metadata Management","text":"<p><code>Change detection</code> - Only re-indexes modified files (checks ETag and lastModified) <code>Smart scheduling</code> - Runs every 15 minutes, can be adjusted <code>Startup sync</code> - Runs once on container startup for immediate availability <code>Detailed logging</code> - Per-file and per-run logs in blob storage <code>Scalable</code> - Handles hundreds of tables and queries efficiently</p>"},{"location":"nl2sql-quickstart/#advanced-query-capabilities-already-working","title":"\ud83e\udde9 Advanced Query Capabilities (Already working!)","text":"<p><code>Complex JOINs</code> - \"Show me orders with customer names and product details\" automatically generates multi-table joins <code>Aggregations</code> - \"What's the average order value by product category?\" generates GROUP BY with AVG/SUM/COUNT <code>Date filtering</code> - \"Show orders from last 30 days\" uses DATEADD and date functions <code>Subqueries</code> - Handles nested queries when needed for complex business logic <code>Pattern matching</code> - \"Find customers whose email contains 'adventure'\" uses LIKE operators</p>"},{"location":"nl2sql-quickstart/#enabling-zero-trust-architecture","title":"\ud83d\udd10 Enabling Zero Trust Architecture","text":"<p>The guide used SQL authentication for simplicity, but production deployments support:</p> <p><code>Azure AD authentication</code> - No passwords, just managed identities <code>Private Endpoints</code> - Database never exposed to internet <code>VNet integration</code> - Container Apps and SQL in same private network <code>Conditional Access</code> - MFA and device compliance requirements</p>"},{"location":"ochestrator/","title":"\ud83c\udfaf Orchestrator","text":"<p>The Orchestrator is the core engine of GPT-RAG, managing multi-agent workflows and retrieval operations using Semantic Kernel and Azure AI services.</p>"},{"location":"ochestrator/#key-features","title":"Key Features","text":"<ul> <li>Multi-Agent Workflows: Coordinates multiple AI agents for complex tasks</li> <li>Context Retrieval: Intelligent retrieval from Azure AI Search</li> <li>Semantic Kernel Integration: Built on Microsoft's Semantic Kernel framework</li> <li>Extensible Architecture: Easy to customize and extend</li> </ul>"},{"location":"ochestrator/#getting-started","title":"Getting Started","text":"<p>New to the Orchestrator? Check out our Orchestrator Visual Guide for a visual walkthrough of the architecture and key components.</p>"},{"location":"ochestrator/#repository","title":"Repository","text":"<p>\ud83d\udd17 GitHub Repository</p>"},{"location":"orchestrator-visual-guide/","title":"Orchestrator: Start Your Code Reading with Visuals","text":"<p>A picture is worth a thousand words. Yet many engineers write another thousand words instead of drawing a single useful diagram. Let\u2019s reverse this evolution \u2014 with visuals.</p> <p>Starting with diagrams \u2014 with a bit of simplification and abstraction \u2014 can significantly accelerate the comprehension of complex codebases. This is especially true when the data flow spans multiple execution environments (container app, AI Foundry, Azure cloud resources), where the initial orientation can otherwise be challenging.</p>"},{"location":"orchestrator-visual-guide/#why-this-article-exists","title":"Why This Article Exists","text":"<p>When I started reading the code, I struggled:</p> <ul> <li>Where is the entry point?</li> <li>What calls what?</li> <li>What is the role of the Orchestrator in the data flow?</li> </ul> <p>If you have ever felt dazed and confused by a codebase with many layers of abstraction, this is for you.</p> <p>If you prefer talking for hours about a diagram instead of drawing it, just leave.</p>"},{"location":"orchestrator-visual-guide/#core-architecture-flow","title":"Core Architecture &amp; Flow","text":"<p>The orchestrator's entry point is in src/main.py: <code>orchestrator_endpoint()</code>. In what follows we will consider the Single-Agent RAG Strategy. <pre><code>@app.post(\n    \"/orchestrator\",\n    dependencies=[Depends(validate_auth)], \n    summary=\"Ask orchestrator a question\",\n    response_description=\"Returns the orchestrator\u2019s response in real time, streamed via SSE.\",\n    responses=ORCHESTRATOR_RESPONSES\n)\nasync def orchestrator_endpoint(\n    body: OrchestratorRequest,\n    x_api_key: Optional[str] = Header(None, alias=\"X-API-KEY\"),\n    dapr_api_token: Optional[str] = Header(None, alias=\"dapr-api-token\"),\n):\n</code></pre></p>"},{"location":"orchestrator-visual-guide/#essential-tasks-of-the-orchestrator","title":"Essential Tasks of the Orchestrator","text":"<p>The <code>Orchestrator</code> class serves as the conversation state manager and strategy coordinator. Its core responsibilities are:</p> <ol> <li>Conversation Lifecycle Management: Creates, loads, and persists conversation documents in the CosmosDB.</li> <li>Strategy Delegation: Routes processing to appropriate agent strategies via factory pattern (<code>AgentStrategyFactory</code>).</li> <li>State Coordination: Ensures conversation state is properly synchronized between database and strategy</li> <li>Response Streaming: Coordinates real-time response delivery while maintaining state consistency</li> </ol>"},{"location":"orchestrator-visual-guide/#single-agent-strategy","title":"Single Agent Strategy","text":"<p>This section explores how the Single-Agent RAG Strategy orchestrates the entire request-response lifecycle, from receiving a user's question to delivering a grounded, streamed answer. The diagrams below illustrate the conversation lifecycle, state management, and the interaction between the Orchestrator container app and AI Foundry services.</p> <p>\ud83d\udfe6 SVG \u00b7 \ud83d\udfe8 PNG \u00b7 \ud83d\udfe5 JPG</p> <p></p> <p>You will have noticed the use of the Factory Design Pattern (<code>AgentStrategyFactory</code>) for the various Strategies, ensuring that all of them comply with the same <code>BaseAgentStrategy</code> interface. For the sake of clarity, I have abstracted away the different roles of the <code>Orchestrator</code> class and the <code>Orchestrator</code> object. <pre><code>------------------------------------------------------------------\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Orchestrator                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  - conversation_id: str                                  \u2502  \u2502\n\u2502  \u2502  - database_client: CosmosDBClient     &lt;&lt;reference&gt;&gt;     \u2502  \u2502\n\u2502  \u2502  - agentic_strategy: BaseAgentStrategy \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502  \u2502\n\u2502  \u2502                                                       \u2502  \u2502  \u2502\n\u2502  \u2502  + create()                                           \u2502  \u2502  \u2502\n\u2502  \u2502  + stream_response()                                  \u2502  \u2502  \u2502\n\u2502  \u2502  + save_feedback()                                    \u2502  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502                                    \u2502\n                      \u2502 uses (delegation)                  \u2502 \n                      \u25bc                                    \u2502\n           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                        \u2502  \n           \u2502 AgentStrategyFactory \u2502 &lt;&lt;factory&gt;&gt;            \u2502\n           \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524                        \u2502\n           \u2502 + get_strategy(key)  \u2502                        \u2502\n           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                        \u2502\n                      \u2502                                    \u2502\n                      \u2502 instantiates                       \u2502\n                      \u25bc                                    \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u2502\n        \u2502    BaseAgentStrategy        \u2502 &lt;&lt;abstract&gt;&gt; \u25c4\u2500\u2500\u2500\u2500\u2500\u2518\n        \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n        \u2502 # strategy_type             \u2502\n        \u2502 # conversation: Dict        \u2502\n        \u2502 # user_context: Dict        \u2502\n        \u2502 # credential                \u2502\n        \u2502 # project_client            \u2502\n        \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n        \u2502 + initiate_agent_flow()*    \u2502 * = abstract method\n        \u2502 # _read_prompt()            \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502\n                       \u2502 inheritance (IS-A)\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502             \u2502                         \u2502\n         \u25bc             \u25bc                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 SingleAgent    \u2502 \u2502  NL2SQL      \u2502  \u2502  McpStrategy    \u2502\n\u2502 RAGStrategy    \u2502 \u2502  Strategy    \u2502  \u2502                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 - tools_list   \u2502 \u2502 - nl2sql     \u2502  \u2502 - kernel        \u2502\n\u2502 - ai_search    \u2502 \u2502   _plugin    \u2502  \u2502 - agent         \u2502\n\u2502 - event_handler\u2502 \u2502 - terminator \u2502  \u2502                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 + initiate_    \u2502 \u2502 + initiate_  \u2502  \u2502 + initiate_     \u2502\n\u2502   agent_flow() \u2502 \u2502   agent_flow \u2502  \u2502   agent_flow()  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n------------------------------------------------------------------\n</code></pre></p> <p>The entry point for the selected Strategy is the method <code>agentic_strategy.initiate_agent_flow()</code>.</p> <p>The strategy object instantiated from the <code>SingleAgentRAGStrategy</code> class runs in the container app and controls the sequence of activities behind the AI Foundry wall. It uses the <code>project_client</code> object as a local proxy (think of it as a remote TV control) to orchestrate operations. The strategy object doesn't handle grounding or LLM calls directly\u2014these are delegated to the AI Foundry agent where the entire RAG pattern is executed.</p> <p>The strategy object <code>SingleAgentRAGStrategy</code></p> <ul> <li> <p>creates a new agent by specifying instructions and a toolbox,</p> </li> <li> <p>retrieves the <code>Thread</code> object based on the thread_id which was retrieved from the CosmosDB,</p> </li> <li> <p>creates a new message from the user's Ask and attaches it to the Thread object,</p> </li> <li> <p>finally calls the project_client.agents.runs.stream() which triggers the RAG pipeline inside of the AI Foundry realm.</p> </li> </ul> <p>Note that <code>Thread</code> objects keep the entire history of conversations. There are two levels of history persistence: one in CosmosDB and another in Thread objects.</p> <p><code>Orchestrator</code> keeps a history (using CosmosDB) identified by <code>conversation_id</code> which arrives in the HTTP Request payload. One of the attributes stored in the CosmosDB is <code>thread_id</code> which points to the <code>Thread</code> object which resides inside of the AI Foundry. AI Foundry maintains its own internal persistency in the Thread objects.</p> <p>The strategy object triggers the RAG pipeline execution inside of AI Foundry with the proxy <code>project_client</code>: <pre><code>project_client.agents.runs.stream(\n    thread_id=thread.id,\n    agent_id=agent.id,\n    ...\n)\n</code></pre> Here is what it does:</p> <ul> <li> <p>Takes the user's Ask.</p> </li> <li> <p>Queries your Azure AI Search index using the <code>AzureAISearchTool</code>.</p> </li> <li> <p>Retrieves relevant document Chunks.</p> </li> <li> <p>Creates the Prompt.</p> </li> <li> <p>Previously retrieved Chunks are included into the Prompt to ground the Response.</p> </li> <li> <p>Prompt is fed into LLM which generates Response.</p> </li> <li> <p>The Response is enhanced by citations and references to the grounding documents.</p> </li> </ul>"},{"location":"orchestrator-visual-guide/#single-agent-strategy-internal-flow","title":"Single Agent Strategy Internal Flow","text":"<p>\ud83d\udfe6 SVG \u00b7 \ud83d\udfe8 PNG \u00b7 \ud83d\udfe5 JPG</p> <p></p> <p>The sequence diagram above is intended to illustrate the core concepts and design patterns present in the codebase. The visualization deliberately simplifies reality through abstraction and by omitting less relevant details.</p>"},{"location":"orchestrator-visual-guide/#links-to-the-code","title":"Links to the code","text":"Concept File Notes Orchestrator entry <code>main.py</code> FastAPI route + request handling Orchestrator implementation <code>orchestration/orchestrator.py</code> Maintains Conversation History + runs streaming pipeline Strategy factory <code>strategies/agent_strategy_factory.py</code> Selects the execution strategy Single-Agent RAG Strategy <code>strategies/single_agent_rag_strategy.py</code> Implements flow to Azure AI Foundry"},{"location":"simple-rag-quickstart/","title":"Simple RAG Quick Start Guide","text":"<p>Get document-based AI question answering working in 60 minutes using GPT-RAG's automated deployment.</p> <p>This quickstart enables a public access solution which is for testing purposes only!</p>"},{"location":"simple-rag-quickstart/#prerequisites","title":"Prerequisites","text":"<p>You must have: - Azure subscription with permissions to create resources - Azure Developer CLI (azd): 1.21.1+ - Azure CLI (az): 2.79.0+ - PowerShell 7.5+ - Docker Desktop installed and running - Git &amp; Python 3.11+</p>"},{"location":"simple-rag-quickstart/#what-youll-accomplish","title":"What You'll Accomplish","text":"<p>By the end of this guide: - Deploy complete GPT-RAG infrastructure (~20 Azure resources) - Upload documents to Azure Blob Storage - Enable automated document ingestion and indexing - Configure AI Foundry search connection - Generate embeddings with text-embedding-3-large - Ask questions about your documents using GPT-4o - Get answers grounded in your data with citations</p>"},{"location":"simple-rag-quickstart/#step-1-initialize-gpt-rag-project-5-min","title":"Step 1: Initialize GPT-RAG Project (5 min)","text":"<pre><code># Create fresh directory\nmkdir C:\\MyCode\\my-gpt-rag\ncd C:\\MyCode\\my-gpt-rag\n\n# Initialize from template\nazd init -t azure/gpt-rag\n</code></pre> <p>You'll be prompted for: 1. Environment name - Choose a short name (e.g., <code>myrag</code>, <code>demorag</code>) 2. Azure subscription - Select from list 3. Azure region - Choose wisely:    - East US 2 - Best OpenAI quota availability    - West US - Good quota, lower latency for West Coast    - East US - Backup option if East US 2 full    - \u26a0\ufe0f North Europe, West Europe - Often quota-constrained</p> <p>\ud83d\udca1 Note: If you have quota limitations, see the Troubleshooting section at the end for how to adjust model capacity.</p>"},{"location":"simple-rag-quickstart/#step-2-authenticate-azure-clis-2-min","title":"Step 2: Authenticate Azure CLIs (2 min)","text":"<pre><code># Login to Azure CLI (yes, both required)\naz login\nazd auth login\n</code></pre>"},{"location":"simple-rag-quickstart/#step-3-provision-infrastructure-30-min","title":"Step 3: Provision Infrastructure (30 min)","text":"<pre><code>azd provision\n</code></pre> <p>What this creates (~20 Azure resources): - Resource Group - Container for all resources - Storage Accounts - For documents and job logs - AI Search Services (2) - Main index (srch-) and AI Foundry index (srch-aif-) - AI Foundry - Hub and project for agent orchestration - OpenAI Models - GPT-4o and text-embedding-3-large deployments - Container Registry - Stores Docker images - Container Apps (4) - Frontend, orchestrator, ingestion, MCP - App Configuration - Centralized configuration store - Key Vault - Secrets management - Cosmos DB - Agent state and metadata - Log Analytics - Monitoring and diagnostics - Managed Identities - Secure service-to-service auth</p> <p>\u23f3 Wait ~27 minutes for provisioning to complete.</p> <p>Save your resource prefix:</p> <p>After provisioning completes, you'll see output like: <pre><code>Resource prefix: y5sbzlaazfxok\n</code></pre></p> <p>Keep this prefix handy - you'll use it to identify your resources in Azure Portal.</p>"},{"location":"simple-rag-quickstart/#step-4-start-docker-and-deploy-services-35-min","title":"Step 4: Start Docker and Deploy Services (35 min)","text":"<p>\u26a0\ufe0f CRITICAL: Docker must be running before <code>azd deploy</code>!</p>"},{"location":"simple-rag-quickstart/#a-start-docker-desktop","title":"A. Start Docker Desktop","text":""},{"location":"simple-rag-quickstart/#b-deploy-services","title":"B. Deploy Services","text":"<pre><code>azd deploy\n</code></pre> <p>What this does: 1. Clones 4 service repositories from GitHub:    - <code>gpt-rag-frontend</code> - React web interface    - <code>gpt-rag-orchestrator</code> - Agent orchestration and RAG logic    - <code>gpt-rag-ingestion</code> - Document processing and indexing    - <code>gpt-rag-mcp</code> - Model Context Protocol integration</p> <ol> <li>Builds Docker images locally:</li> <li>Creates containers for each service</li> <li>Tags them with version info</li> <li> <p>Requires ~5-10 GB disk space</p> </li> <li> <p>Pushes images to Azure Container Registry:</p> </li> <li>Uploads to <code>cr{prefix}.azurecr.io</code></li> <li> <p>Typically 1-2 GB total</p> </li> <li> <p>Deploys to Container Apps:</p> </li> <li>Creates 4 container apps</li> <li>Configures networking, secrets, environment variables</li> <li>Sets up auto-scaling rules</li> </ol> <p>\u23f3 Wait ~30 minutes for deployment to complete.</p>"},{"location":"simple-rag-quickstart/#step-5-upload-documents-and-verify-indexing-10-min","title":"Step 5: Upload Documents and Verify Indexing (10 min)","text":""},{"location":"simple-rag-quickstart/#a-upload-your-documents","title":"A. Upload Your Documents","text":"<p>Azure Portal \u2192 Storage accounts \u2192 st<code>&lt;prefix&gt;</code> \u2192 Containers \u2192 documents \u2192 Upload</p> <p>Supported formats: - PDF - Most common (OCR with Document Intelligence) - Word (.docx) - Extracts text and tables - PowerPoint (.pptx) - Extracts slides and speaker notes - Excel (.xlsx) - Extracts sheets and data (v4.0+) - Text (.txt, .md) - Direct text ingestion - Images (.jpg, .png, .bmp, .tiff) - OCR extraction - HTML - Web page content extraction</p> <p>What happens after upload: 1. File stored in <code>documents</code> container 2. Ingestion service monitors for new files 3. On next CRON run or restart, files are processed 4. Azure Document Intelligence extracts text (OCR for images/PDFs) 5. Text chunked into semantic segments 6. Embeddings generated with text-embedding-3-large 7. Chunks uploaded to AI Search index <code>ragindex-{prefix}</code></p>"},{"location":"simple-rag-quickstart/#b-trigger-document-indexing","title":"B. Trigger Document Indexing","text":"<p>The indexing service runs automatically: - On container startup (immediate first run) - Hourly on CRON (at :10 minutes past the hour)</p> <p>Option 1: Wait for next CRON run (up to 60 minutes)</p> <p>Option 2: Force immediate indexing by restarting:</p> <p>Azure Portal \u2192 Container Apps \u2192 ca-<code>&lt;prefix&gt;</code>-dataingest</p> <ol> <li>Click Stop</li> <li>Wait 10 seconds</li> <li>Click Start</li> </ol> <p>Why restart? The indexer runs on CRON schedule (hourly at :10 past). Restarting triggers it to run immediately instead of waiting up to an hour.</p>"},{"location":"simple-rag-quickstart/#c-verify-indexing-completed","title":"C. Verify Indexing Completed","text":"<p>Azure Portal \u2192 AI Search \u2192 srch-<code>&lt;prefix&gt;</code> \u2192 Indexes \u2192 ragindex-<code>&lt;prefix&gt;</code></p> <ul> <li>Document count &gt; 0 (indicates chunks were indexed)</li> </ul>"},{"location":"simple-rag-quickstart/#step-6-configure-ai-foundry-search-connection-for-public-access-rag-5-min","title":"Step 6: Configure AI Foundry Search Connection for Public Access RAG (5 min)","text":"<p>\u26a0\ufe0f CRITICAL STEP: The deployment creates two AI Search services. You must configure AI Foundry to use the correct one for public access!</p>"},{"location":"simple-rag-quickstart/#a-why-two-search-services","title":"A. Why Two Search Services?","text":"<ul> <li>srch-<code>&lt;prefix&gt;</code> - Main search service with your indexed documents (use this one!)</li> <li>srch-aif-<code>&lt;prefix&gt;</code> - AI Foundry's empty search service (created by default, ignore)</li> </ul> <p>The orchestrator needs the connection ID for the main search service.</p>"},{"location":"simple-rag-quickstart/#b-add-search-connection-in-ai-foundry","title":"B. Add Search Connection in AI Foundry","text":"<ol> <li>Azure Portal \u2192 AI services \u2192 aif-<code>&lt;prefix&gt;</code> \u2192 Overview</li> <li>Click the \"View in Azure AI Foundry\" link (opens ai.azure.com)</li> <li>Should land in your project (likely named aifoundry-default-project)</li> <li>Left menu \u2192 Connected resources or Connections</li> <li>Click + New connection</li> <li>Select Azure AI Search</li> <li>Select srch-<code>&lt;prefix&gt;</code> (NOT srch-aif-*)</li> <li>Authentication: Microsoft Entra ID (NOT API Key)</li> <li>Connection name: Use the resource name (e.g., <code>srchqitxxnnt4igs6</code>)</li> <li>Click Save</li> </ol>"},{"location":"simple-rag-quickstart/#c-copy-connection-id","title":"C. Copy Connection ID","text":"<p>After saving, the connection details page shows the connection ID.</p> <p>Example: <pre><code>/subscriptions/f94c002c-2212-4bfb-b7a4-f8898b7ea4e5/resourceGroups/rg-demorag/providers/Microsoft.CognitiveServices/accounts/aif-qitxxnnt4igs6/projects/aifoundry-default-project/connections/srchqitxxnnt4igs6\n</code></pre></p> <p>Copy this entire connection ID - you'll paste it in the next step.</p>"},{"location":"simple-rag-quickstart/#step-7-update-app-configuration-and-restart-orchestrator-5-min","title":"Step 7: Update App Configuration and Restart Orchestrator (5 min)","text":""},{"location":"simple-rag-quickstart/#a-update-app-configuration","title":"A. Update App Configuration","text":"<p>Azure Portal \u2192 App Configuration \u2192 appcs-<code>&lt;prefix&gt;</code> \u2192 Configuration explorer</p> <ol> <li>Find key: SEARCH_CONNECTION_ID</li> <li>Filter by label: gpt-rag</li> <li>Click the key \u2192 Click Edit</li> <li>Value field: Paste the connection ID you copied from AI Foundry</li> <li>Verify:</li> <li>Content type: <code>text/plain</code></li> <li>Label: <code>gpt-rag</code></li> <li>Click Apply \u2192 Click Save</li> </ol>"},{"location":"simple-rag-quickstart/#b-restart-orchestrator","title":"B. Restart Orchestrator","text":"<p>Azure Portal \u2192 Container Apps \u2192 ca-<code>&lt;prefix&gt;</code>-orchestrator</p> <ol> <li>Click Deactivate</li> <li>Wait 10 seconds</li> <li>Click Activate</li> </ol> <p>Why restart? Container apps read configuration from App Configuration at startup. Restarting loads the new SEARCH_CONNECTION_ID value you just updated.</p>"},{"location":"simple-rag-quickstart/#step-8-access-frontend-and-test-3-min","title":"Step 8: Access Frontend and Test! (3 min)","text":"<p>Azure Portal \u2192 Container Apps \u2192 ca-<code>&lt;prefix&gt;</code>-frontend \u2192 Overview</p> <p>Copy the Application URL and open it in your browser. You should see the GPT-RAG chat interface.</p> <p>Try these test questions: 1. \"What is this document about?\" 2. \"Summarize the key points from my document\" 3. \"What does the document say about [specific topic]?\"</p> <p>Expected response: - Natural language answer based on your document - Citations showing which chunks were used - Source references with page numbers (if PDF) - Response generated by GPT-4o using retrieved context</p>"},{"location":"simple-rag-quickstart/#troubleshooting-common-issues","title":"Troubleshooting Common Issues","text":""},{"location":"simple-rag-quickstart/#issue-1-quota-exceeded-errors","title":"Issue 1: Quota Exceeded Errors","text":"<p>Error during provision: <pre><code>Deployment failed: Quota exceeded for model gpt-4o\n</code></pre></p> <p>Background: The default deployment requires 80 TPM total (40 for GPT-4o + 40 for text-embedding-3-large). Many subscriptions don't have this quota available.</p> <p>Solution A: Reduce Model Capacity</p> <p>Edit <code>infra/main.parameters.json</code> BEFORE running <code>azd provision</code>:</p> <pre><code>\"modelDeploymentList\": {\n  \"value\": [\n    {\n      \"name\": \"chat\",\n      \"model\": {\n        \"format\": \"OpenAI\",\n        \"name\": \"gpt-4o\",\n        \"version\": \"2024-11-20\"\n      },\n      \"sku\": {\n        \"name\": \"GlobalStandard\",\n        \"capacity\": 8\n      }\n    },\n    {\n      \"name\": \"text-embedding\",\n      \"model\": {\n        \"format\": \"OpenAI\",\n        \"name\": \"text-embedding-3-large\",\n        \"version\": \"1\"\n      },\n      \"sku\": {\n        \"name\": \"Standard\",\n        \"capacity\": 8\n      }\n    }\n  ]\n}\n</code></pre> <p>Capacity guidelines: - 8 TPM - Good for testing/demos (supports ~5-10 users) - 16 TPM - Better for development (supports ~15-20 users) - 40 TPM - Production (default, supports ~50+ users) - Minimum: 4 TPM - Will work but responses may be slower</p> <p>Solution B: Check Available Quota</p> <pre><code># List your OpenAI resources and regions\naz cognitiveservices account list `\n  --subscription \"&lt;your-subscription-id&gt;\" `\n  --query \"[?kind=='OpenAI'].{Name:name, ResourceGroup:resourceGroup, Location:location}\" `\n  -o table\n</code></pre> <p>Check quota in Azure Portal: - Go to any OpenAI resource \u2192 Quotas - Look at TPM (Tokens Per Minute) for gpt-4o and text-embedding-3-large - Note which regions have available quota</p> <p>Solution C: Try Different Region</p> <p>If you've already started provisioning, delete the failed resource group and try a different region:</p> <pre><code>az group delete --name &lt;your-rg&gt; --yes\nazd env set AZURE_LOCATION eastus\nazd provision\n</code></pre>"},{"location":"simple-rag-quickstart/#issue-2-serviceinvocationexception-error","title":"Issue 2: \"ServiceInvocationException\" Error","text":"<p>Error message: <pre><code>ServiceInvocationException: Error at: project_client.agents.threads.create()\n</code></pre></p> <p>Root cause: AI Foundry capabilities host lacks vector store connections (immutable configuration).</p> <p>Workaround: 1. Check orchestrator logs: <code>ca-&lt;prefix&gt;-orchestrator</code> \u2192 Logs \u2192 Console logs 2. Verify SEARCH_CONNECTION_ID is correctly set in App Configuration 3. Try restarting orchestrator again 4. If persists, check AI Foundry Connections page for connection status</p> <p>Note: This is a known issue with the current GPT-RAG template. The AI Foundry agent infrastructure may need manual configuration.</p>"},{"location":"simple-rag-quickstart/#issue-3-no-documents-indexed","title":"Issue 3: No Documents Indexed","text":"<p>Symptoms: - AI Search index shows 0 documents - Answers are generic, not grounded in your data</p> <p>Checks: 1. Verify upload: Storage account \u2192 <code>documents</code> container \u2192 your file should be there 2. Check indexer logs: <code>ca-&lt;prefix&gt;-dataingest</code> \u2192 Logs \u2192 Look for errors 3. Verify format: Ensure file is supported (PDF, DOCX, TXT, etc.) 4. Restart indexer: Deactivate/Activate <code>ca-&lt;prefix&gt;-dataingest</code></p>"},{"location":"simple-rag-quickstart/#what-you-just-enabled","title":"What You Just Enabled \ud83e\ude84","text":"<p>Congratulations! You've deployed a production-ready RAG system. Your solution now provides:</p>"},{"location":"simple-rag-quickstart/#intelligent-document-understanding","title":"\ud83e\udde0 Intelligent Document Understanding","text":"<p><code>Semantic chunking</code> - Documents split into meaningful segments (not arbitrary 512-char blocks) <code>Vector embeddings</code> - text-embedding-3-large generates 3072-dimensional embeddings <code>Hybrid search</code> - Combines keyword (BM25) and semantic (vector) search for best results <code>OCR extraction</code> - Azure Document Intelligence handles PDFs, images, scanned documents <code>Multi-format support</code> - PDF, Word, PowerPoint, Excel, text, images, HTML</p>"},{"location":"simple-rag-quickstart/#grounded-response-generation","title":"\ud83c\udfaf Grounded Response Generation","text":"<p><code>Retrieval-Augmented Generation (RAG)</code> - GPT-4o generates answers using retrieved document chunks <code>Citation tracking</code> - Every answer links back to source documents and specific passages <code>Relevance filtering</code> - Only high-confidence matches are sent to GPT-4o (reduces hallucination) <code>Context windowing</code> - Smart selection of most relevant chunks (handles long documents)</p>"},{"location":"simple-rag-quickstart/#automated-ingestion-pipeline","title":"\ud83d\udd04 Automated Ingestion Pipeline","text":"<p><code>Change detection</code> - Only re-indexes modified files (checks ETag and lastModified) <code>CRON scheduling</code> - Runs hourly at :10 past (configurable) <code>Startup sync</code> - Indexes on container start for immediate availability <code>Detailed logging</code> - Per-file and per-run logs in blob storage <code>Error handling</code> - Failed files logged without blocking successful files</p>"},{"location":"simple-rag-quickstart/#enterprise-ready-architecture","title":"\ud83d\udd10 Enterprise-Ready Architecture","text":"<p><code>Managed identities</code> - No passwords stored, secure service-to-service auth <code>Role-based access</code> - Uses Azure RBAC for all resources <code>Centralized config</code> - App Configuration for runtime settings (no redeployment needed) <code>Secrets management</code> - Key Vault for sensitive data <code>Monitoring</code> - Log Analytics and Application Insights built-in <code>Scalability</code> - Container Apps auto-scale based on load</p>"},{"location":"simple-rag-quickstart/#user-friendly-interface","title":"\ud83c\udfa8 User-Friendly Interface","text":"<p><code>React frontend</code> - Modern, responsive chat interface <code>Real-time responses</code> - Streaming GPT-4o responses (see text appear live) <code>Citation preview</code> - Click citations to see source context <code>Multi-turn conversations</code> - Maintains context across questions <code>Feedback loop</code> - Users can rate answers for quality tracking</p>"},{"location":"team/","title":"Meet the Team","text":"Core Team Leads the direction, development, and continuous evolution of GPT-RAG. <sub>Paulo Lacerda</sub> <sub>Project Lead</sub> <sub>Vlad Borys</sub> <sub>Pull Request Reviewer</sub> Engineering Advisor Provides technical guidance and ensures architectural alignment with best practices. <sub>Pablo Castro</sub> <sub>Engineering Advisor</sub> Champions Community advocates helping users succeed, sharing knowledge, and growing the GPT-RAG ecosystem. <sub>Ramesh Jajula</sub> <sub>Vinod Chekkala</sub> <sub>Saurabh Singh</sub> <sub>Varun Nambia</sub> Founders The visionaries who laid the foundation and shaped GPT-RAG from the ground up. <sub>Paulo Lacerda</sub> <sub>Gonzalo Becerra</sub> <sub>Martin Sciarrilo</sub> Contributors Every contribution matters \u2014 code, documentation, ideas, or feedback. GPT-RAG Orchestrator Ingestion UI MCP <p>Every contribution matters! Whether it's code, docs, ideas, or feedback \u2014 you help make GPT-RAG better.</p> <p>\ud83d\udc49 Learn how to contribute</p>"},{"location":"userfeedback/","title":"User Feedback Configuration","text":"<p>GPT-RAG includes a User Feedback Loop feature that lets users evaluate assistant responses through the UI. Feedback is sent to the backend, processed by the orchestrator, and stored in Cosmos DB for analysis and continuous improvement.</p> <p> User feedback stored in Cosmos DB</p> <p>By default, basic feedback (thumbs up/down) is enabled, while detailed ratings (star rating and comments) are disabled. Administrators control these options through Azure App Configuration.</p>"},{"location":"userfeedback/#feedback-types","title":"Feedback Types","text":"<p>When enabled, users can provide star ratings and text comments for richer feedback that captures both satisfaction and reasoning.</p> <p> User providing rating and comment feedback</p>"},{"location":"userfeedback/#configuration-settings","title":"Configuration Settings","text":"<p>The behavior of the feedback loop is controlled by key-values in Azure App Configuration:</p> <ul> <li>ENABLE_USER_FEEDBACK \u2192 Default: <code>true</code>   Controls whether the feedback feature is available at all.</li> </ul> <p> Key to enable or disable user feedback globally</p> <ul> <li>USER_FEEDBACK_RATING \u2192 Default: <code>false</code>   Controls whether users can provide detailed feedback with ratings and comments.</li> </ul> <p> Key to enable or disable detailed rating feedback</p>"},{"location":"userfeedback/#default-values","title":"Default Values","text":"<ul> <li><code>ENABLE_USER_FEEDBACK = true</code></li> <li><code>USER_FEEDBACK_RATING = false</code></li> </ul> <p>This means feedback is collected by default, but star ratings and comments must be explicitly enabled by setting <code>USER_FEEDBACK_RATING</code> to <code>true</code>.</p>"},{"location":"whatisnew/","title":"What's New","text":"<p>\ud83d\udccc Check out what's coming next  (Azure org only)</p>"},{"location":"whatisnew/#october-2025","title":"October 2025","text":"<p>Release 2.2.0 - Agentic Retrieval and Network Flexibility</p> <p>This release introduces major enhancements to support more flexible and enterprise-ready deployments.</p> <p>Bring Your Own VNet   Enables organizations to deploy GPT-RAG within their existing virtual network, maintaining full control over network boundaries, DNS, and routing policies.   #370</p> <p>Agentic Retrieval   Adds intelligent, agent-driven retrieval orchestration that dynamically selects and combines information sources for more grounded and context-aware responses.   #359</p>"},{"location":"whatisnew/#september-2025","title":"September 2025","text":"<p>Release 2.1.0 - User Feedback Loop</p> <p>Introduces a mechanism for end-users to provide thumbs-up or thumbs-down feedback on assistant responses, storing these signals alongside conversation history to continuously improve response quality.</p> <ul> <li>How to configure it: User Feedback Configuration</li> <li>Demo video:</li> </ul>"}]}