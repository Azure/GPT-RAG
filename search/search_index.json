{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#gpt-rag-solution-accelerator","title":"GPT-RAG Solution Accelerator","text":""},{"location":"#overview","title":"Overview","text":"<p>GPT-RAG is a powerful, enterprise-ready accelerator that transforms how organizations build Retrieval-Augmented Generation (RAG) solutions on Azure. By leveraging Azure OpenAI, AI Search, and AI Foundry, it delivers a secure, modular foundation for creating intelligent conversational assistants and data-driven applications.</p> <p></p> <p>Built from the ground up with Zero-Trust security principles and Infrastructure as Code (IaC), GPT-RAG accelerates your journey to production-ready AI solutions. Whether you're working with text, images, or voice, this comprehensive platform combines enterprise-grade security, intelligent orchestration, and multimodal capabilities to deliver exceptional user experiences faster than ever.</p>"},{"location":"#core-services","title":"Core Services","text":"Services Description Orchestrator Manages multi-agent workflows and retrieves context using Semantic Kernel and Azure AI. Web UI User interface for chat interactions, supports streaming and custom themes. Data Ingestion Extracts, chunks, and indexes enterprise data for optimized retrieval. MCP Server Implements the Model Context Protocol for tool hosting and business logic integration."},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions from the community! Check our Contribution Guidelines for CLA, code of conduct, and PR guidelines.</p>"},{"location":"architecture/","title":"Overview","text":""},{"location":"architecture/#architecture","title":"\ud83c\udfdb\ufe0f Architecture","text":""},{"location":"architecture/#key-capabilities","title":"\u26a1 Key Capabilities","text":"<p>Enterprise-Grade Security \ud83d\udee1\ufe0f Zero-Trust architecture with private endpoints, Azure Key Vault integration, and comprehensive monitoring.</p> <p>Flexible &amp; Customizable \ud83d\udd27 Modular design with customizable orchestration, multiple interface options, and bring-your-own-resources support.</p> <p>Multimodal Experience \ud83c\udfaf Native support for text, images, and voice with SharePoint and Fabric connectors for seamless data integration.</p> <p>Production Ready \ud83d\ude80 Auto-scaling deployment, continuous integration pipelines, and automated quality evaluation built-in.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>We appreciate contributions and suggestions for this project! Before contributing, you'll need to sign a Contributor License Agreement (CLA) to confirm that you have the rights to, and do, grant us permission to use your contribution. More details can be found at Microsoft CLA.</p> <p>This project adheres to the Microsoft Open Source Code of Conduct. For more information, please visit the Code of Conduct FAQ or contact opencode@microsoft.com with any questions or comments.</p> <p>Below, you'll find details on how our code update process works and instructions on how to contribute.</p>"},{"location":"contributing/#contribution-guidelines","title":"Contribution Guidelines","text":"<p>To maintain project quality, the following items will be considered during the PR review.</p> <p>Adhering to these best practices will streamline the review process.</p> <ul> <li> <p>Target the <code>develop</code> Branch: Always direct your pull request to the <code>develop</code> branch to ensure that changes are properly integrated into the project's development workflow.</p> </li> <li> <p>Keep Pull Requests Small: Aim to make your pull requests as focused and concise as possible. This makes it easier to review and ensures quicker integration into the codebase.</p> </li> <li> <p>Associate with Prioritized Issues: Ensure that each pull request is linked to a specific, prioritized issue in the project backlog. This helps maintain alignment with project goals and ensures that work is being done on tasks of the highest importance.</p> </li> <li> <p>Include Documentation: Every new feature or functionality must be accompanied by clear documentation explaining its purpose and configuration. This ensures others can use it independently in a self-service manner.</p> </li> <li> <p>Bugs and Documentation Corrections: Pull requests that address bugs or correct documentation do not need to be associated with prioritized issues. These can be submitted directly to maintain the quality and accuracy of the project.</p> </li> <li> <p>Multi-Repo Dependencies: If your pull request has dependencies on updates in other repositories, make sure to mention this in the pull request description. Additionally, create a corresponding pull request in the other repository to ensure synchronized updates across all related projects.</p> </li> </ul>"},{"location":"contributing/#code-update-workflow","title":"Code Update Workflow","text":"<p>We use a simplified version of the Fork and Branch Workflow alongside Git Flow for branching strategy. The <code>main</code> branch always contains deployment-ready code, while the <code>develop</code> branch serves as our integration branch.</p> <p>Contributors create feature branches from <code>develop</code> in their forks. Once changes are completed, they submit a pull request to the <code>develop</code> branch in the upstream repository. After review and approval, reviewers merge the changes into <code>develop</code>. Weekly, maintainers group these changes into a pull request from <code>develop</code> to <code>main</code> for final review and merging.</p>"},{"location":"contributing/#step-by-step-process-overview","title":"Step-by-Step Process Overview","text":"<p>This section outlines the contribution process, highlighting the key actions for both contributors and reviewers. The accompanying diagram visually represents the workflow.</p> <p></p>"},{"location":"contributing/#contributor","title":"Contributor","text":"<ol> <li>Fork the Repository: Create a copy of the original repository in your GitHub account.</li> <li>Clone Locally: Download the forked repository to your machine.</li> <li>Add Upstream: Link the original repository as \"upstream\" to keep your fork synced.</li> <li>Create a Feature Branch: Start a new branch for your changes.</li> <li>Commit and Push Changes: Implement your changes and push them to your GitHub fork.</li> <li>Open a Pull Request: Submit your changes for review. If approved, they\u2019ll be merged into the <code>develop</code> branch and later into <code>main</code> based on the project\u2019s release process.</li> <li>Keep Your Fork Updated: Regularly sync your fork with the original repository to stay current.</li> </ol>"},{"location":"contributing/#contributors-step-by-step-guide","title":"Contributor's Step-by-Step Guide","text":"<p>Here\u2019s an example of how to implement a feature called <code>conversation-metadata</code> in the <code>gpt-rag-orchestrator</code> repository. The process is similar for other repositories, such as <code>gpt-rag-ingestion</code>.</p> <ol> <li>Create a Fork by clicking the Fork button on the repository page on GitHub. Be sure to include all branches.</li> </ol> <p><code>https://github.com/placerda/gpt-rag-orchestrator.git</code></p> <ol> <li>Clone Your Fork Locally using the standard clone command.</li> </ol> <p><code>git clone https://github.com/placerda/gpt-rag-orchestrator.git</code></p> <ol> <li>Set Upstream Remote: Link the original repository as \"upstream\" for future use.</li> </ol> <p><code>git remote add upstream git@github.com:Azure/gpt-rag-orchestrator.git</code></p> <ol> <li>Create a Feature Branch in your forked repository.</li> </ol> <p><code>git checkout -b feature/conversation-metadata</code></p> <ol> <li>Make Changes Locally: Modify the code in your local clone. Commit your changes and push them to your fork on GitHub.</li> </ol> <p><code>bash    git add .    git commit -m 'Implemented conversation metadata'    git push origin feature/conversation-metadata</code></p> <ol> <li>Create a Pull Request: Go to your fork on GitHub and click \"Pull Request.\" This request, aimed at the <code>develop</code> branch, will be reviewed and potentially merged by the repository maintainers.</li> </ol> <p>Done! Now, wait for the review and approval of your pull request. Changes may be requested.</p>"},{"location":"contributing/#keeping-your-fork-updated","title":"Keeping Your Fork Updated","text":"<p>It\u2019s recommended that you update your local clone after your pull request is approved. Follow these steps:</p> <pre><code>git pull upstream main\ngit push origin main\ngit pull upstream develop\ngit push origin develop\n</code></pre>"},{"location":"contributing/#cleaning-your-repo-after-pr-acceptance","title":"Cleaning Your Repo After PR Acceptance","text":"<p>Once your changes are merged, you can delete the feature branch from your local clone using these commands:</p> <pre><code>git switch develop\ngit branch -d feature/conversation-metadata\ngit push --delete origin feature/conversation-metadata\n</code></pre>"},{"location":"deploy/","title":"\ud83d\ude80 Deployment Guide","text":"<p>Choose your preferred deployment method based on project requirements and environment constraints.</p> <p>Note: You can change parameter values in <code>main.parameters.json</code> or set them with <code>azd env set</code> before running <code>azd provision</code>. This applies only to parameters that support environment variable substitution.</p>"},{"location":"deploy/#prerequisites","title":"Prerequisites","text":"<p>Required Permissions:    - Azure subscription with Contributor and User Access Admin roles    - Agreement to Responsible AI terms for Azure AI Services</p> <p>Required Tools:    - Azure Developer CLI    - PowerShell 7+ (Windows only)    - Git    - Python 3.12</p>"},{"location":"deploy/#quick-start-basic-deployment","title":"Quick Start - Basic Deployment","text":"<p>Quick setup for demos without network isolation.</p> <pre><code>azd init -t azure/gpt-rag\nazd provision\n</code></pre> <p>Demo video:</p>"},{"location":"deploy/#zero-trust-deployment","title":"Zero Trust Deployment","text":"<p>For deployments that require network isolation.</p>"},{"location":"deploy/#before-provisioning","title":"Before Provisioning","text":"<p>Enable network isolation in your environment:</p> <pre><code>azd env set NETWORK_ISOLATION true\n</code></pre>"},{"location":"deploy/#provision-infrastructure","title":"Provision Infrastructure","text":"<pre><code>azd provision\n</code></pre>"},{"location":"deploy/#post-provision-configuration","title":"Post-Provision Configuration","text":"<p>The Bicep template provisions a Jumpbox VM by default. You can connect to it to perform the post-provision steps, deploy services, and run tests.</p> <p>Option A \u2013 Using the deployed Jumpbox VM</p> <ol> <li>Connect via Azure Bastion.</li> <li>Open a terminal in the VM and run:</li> </ol> <p><code>shell    cd C:\\github\\gpt-rag    .\\scripts\\postProvision.ps1</code></p> <p>Option B \u2013 From your local machine (must have VNet access)</p> <ol> <li>From the <code>gpt-rag</code> directory, run:</li> </ol> <p><code>shell    .\\scripts\\postProvision.ps1</code></p> <p>or (Bash)</p> <p><code>shell    .\\scripts\\postProvision.sh</code></p> <ol> <li>If you have re-initialized or cloned the repo again, refresh your <code>azd</code> environment so it points to the existing deployment:</li> </ol> <p><code>shell    azd init -t azure/gpt-rag    azd env refresh</code></p> <ol> <li>When prompted, select the same Subscription, Resource Group, and Location as the original provisioning so <code>azd</code> correctly links to your environment.</li> </ol>"},{"location":"deploy/#deploy-gpt-rag-services","title":"Deploy GPT-RAG Services","text":"<p>Once the GPT-RAG infrastructure is provisioned, you can deploy the services.</p> <p>To deploy all services at once, navigate to the <code>gpt-rag</code> directory (with azd environment configured) and run:</p> <pre><code>azd deploy\n</code></pre> <p>This command deploys each service in sequence.</p> <p>If you prefer to deploy a single service\u2014for example, when updating only that service\u2014navigate to the corresponding service repository and follow the instructions in its \"How to Deploy\" section.</p>"},{"location":"deploy/#permissions","title":"Permissions","text":"<p>AI Foundry Role and AI Search Assignments</p> Resource Role Assignee Description GenAI App Search Service Search Index Data Reader AI Foundry Project Read index data GenAI App Search Service Search Service Contributor AI Foundry Project Create AI search connection GenAI App Storage Account Storage Blob Data Reader AI Foundry Account Read blob data GenAI App Storage Account Storage Blob Data Reader Search Service Read blob data for search integration AI Foundry Storage Account Storage Blob Data Contributor AI Foundry Project Enable agent to store/retrieve blob artifacts in customer storage AI Foundry Storage Account Containers Storage Blob Data Owner (workspace) AI Foundry Project Scoped owner access to workspace containers for session-specific data AI Foundry Cosmos DB Account Cosmos DB Operator AI Foundry Project Control-plane operations for enterprise memory database (threads) AI Foundry Cosmos DB Containers Cosmos DB Built-in Data Contributor AI Foundry Project Read/write conversation threads within enterprise memory containers AI Foundry Search Service Search Service Contributor AI Foundry Project Create/update indexes for vector search workflows AI Foundry Search Service Search Index Data Contributor AI Foundry Project Read/write index data for embedding-based queries <p>Container App Role Assignments</p> Resource Role Assignee Description GenAI App Configuration Store App Configuration Data Reader ContainerApp: orchestrator Read configuration data GenAI App Configuration Store App Configuration Data Reader ContainerApp: frontend Read configuration data GenAI App Configuration Store App Configuration Data Reader ContainerApp: dataingest Read configuration data GenAI App Configuration Store App Configuration Data Reader ContainerApp: mcp Read configuration data GenAI App Container Registry AcrPull ContainerApp: mcp Pull container images GenAI App Container Registry AcrPull ContainerApp: orchestrator Pull container images GenAI App Container Registry AcrPull ContainerApp: frontend Pull container images GenAI App Container Registry AcrPull ContainerApp: dataingest Pull container images GenAI App Key Vault Key Vault Secrets User ContainerApp: orchestrator Read secrets GenAI App Key Vault Key Vault Secrets User ContainerApp: frontend Read secrets GenAI App Key Vault Key Vault Secrets User ContainerApp: dataingest Read secrets GenAI App Key Vault Key Vault Secrets User ContainerApp: mcp Read secrets GenAI App Search Service Search Index Data Reader ContainerApp: orchestrator Read index data GenAI App Search Service Search Index Data Contributor ContainerApp: dataingest Read/write index data GenAI App Search Service Search Index Data Contributor ContainerApp: mcp Read/write index data GenAI App Storage Account Storage Blob Data Reader ContainerApp: orchestrator Read blob data GenAI App Storage Account Storage Blob Data Reader ContainerApp: frontend Read blob data GenAI App Storage Account Storage Blob Data Contributor ContainerApp: dataingest Read/write blob data GenAI App Storage Account Storage Blob Data Contributor ContainerApp: mcp Read/write blob data GenAI App Storage Account Storage Queue Data Contributor ContainerApp: mcp Read/write storage queue data GenAI App Cosmos DB Cosmos DB Built-in Data Contributor ContainerApp: orchestrator Read/write Cosmos DB data AI Foundry Account Cognitive Services User ContainerApp: orchestrator Access Cognitive Services operations AI Foundry Account Cognitive Services User ContainerApp: dataingest Access Cognitive Services operations AI Foundry Account Cognitive Services OpenAI User ContainerApp: orchestrator Use OpenAI APIs AI Foundry Account Cognitive Services OpenAI User ContainerApp: dataingest Use OpenAI APIs AI Foundry Account Cognitive Services User ContainerApp: mcp Access Cognitive Services AI Foundry Account Cognitive Services OpenAI User ContainerApp: mcp Use OpenAI APIs <p>Executor Role Assignments</p> Resource Role Assignee Description GenAI App Configuration Store App Configuration Data Owner Executor Full control over configuration settings GenAI App Container Registry AcrPush Executor Push container images GenAI App Key Vault Key Vault Contributor Executor Manage Key Vault settings GenAI App Key Vault Key Vault Secrets Officer Executor Create Key Vault secrets GenAI App Search Service Search Service Contributor Executor Create/update search service elements GenAI App Search Service Search Index Data Contributor Executor Read/write search index data GenAI App Storage Account Storage Blob Data Contributor Executor Read/write blob data GenAI App Cosmos DB Cosmos DB Built-in Data Contributor Executor Read/write Cosmos DB data AI Foundry Project Azure AI Project Manager Executor Manage AI Foundry projects and assign roles <p>Jumpbox VM Role Assignments</p> Resource Role Assignee Description GenAI App Container Apps Container Apps Contributor Jumpbox VM Full control over Container Apps (deploy/manage apps) Azure Managed Identity Managed Identity Operator Jumpbox VM Assign and manage user-assigned managed identities GenAI App Container Registry Container Registry Repository Writer Jumpbox VM Write to specific repositories GenAI App Container Registry Container Registry Tasks Contributor Jumpbox VM Manage ACR tasks GenAI App Container Registry Container Registry Data Access Configuration Administrator Jumpbox VM Manage data access configuration for ACR GenAI App Container Registry AcrPush Jumpbox VM Push container images GenAI App Configuration Store App Configuration Data Owner Jumpbox VM Full control over configuration settings GenAI App Key Vault Key Vault Contributor Jumpbox VM Manage Key Vault settings GenAI App Key Vault Key Vault Secrets Officer Jumpbox VM Create Key Vault secrets GenAI App Search Service Search Service Contributor Jumpbox VM Create/update search service elements GenAI App Search Service Search Index Data Contributor Jumpbox VM Read/write search index data GenAI App Storage Account Storage Blob Data Contributor Jumpbox VM Read/write blob data AI Foundry Account Azure AI Project Manager Jumpbox VM Manage AI Foundry projects and assign roles AI Foundry Account Cognitive Services Contributor Jumpbox VM Manage Cognitive Services resources GenAI App Cosmos DB Cosmos DB Built-in Data Contributor Jumpbox VM Read/write Cosmos DB data"},{"location":"userfeedback/","title":"User Feedback Configuration","text":"<p>GPT-RAG includes a User Feedback Loop feature that lets users evaluate assistant responses through the UI. Feedback is sent to the backend, processed by the orchestrator, and stored in Cosmos DB for analysis and continuous improvement.</p> <p> User feedback stored in Cosmos DB</p> <p>By default, basic feedback (thumbs up/down) is enabled, while detailed ratings (star rating and comments) are disabled. Administrators control these options through Azure App Configuration.</p>"},{"location":"userfeedback/#feedback-types","title":"Feedback Types","text":"<p>When enabled, users can provide star ratings and text comments for richer feedback that captures both satisfaction and reasoning.</p> <p> User providing rating and comment feedback</p>"},{"location":"userfeedback/#configuration-settings","title":"Configuration Settings","text":"<p>The behavior of the feedback loop is controlled by key-values in Azure App Configuration:</p> <ul> <li>ENABLE_USER_FEEDBACK \u2192 Default: <code>true</code>   Controls whether the feedback feature is available at all.</li> </ul> <p> Key to enable or disable user feedback globally</p> <ul> <li>USER_FEEDBACK_RATING \u2192 Default: <code>false</code>   Controls whether users can provide detailed feedback with ratings and comments.</li> </ul> <p> Key to enable or disable detailed rating feedback</p>"},{"location":"userfeedback/#default-values","title":"Default Values","text":"<ul> <li><code>ENABLE_USER_FEEDBACK = true</code></li> <li><code>USER_FEEDBACK_RATING = false</code></li> </ul> <p>This means feedback is collected by default, but star ratings and comments must be explicitly enabled by setting <code>USER_FEEDBACK_RATING</code> to <code>true</code>.</p>"},{"location":"whatisnew/","title":"What's New","text":""},{"location":"whatisnew/#october-2025","title":"October 2025","text":"<p>Release 2.2.0 - Agentic Retrieval and Network Flexibility</p> <p>This release introduces major enhancements to support more flexible and enterprise-ready deployments.</p> <p>Bring Your Own VNet   Enables organizations to deploy GPT-RAG within their existing virtual network, maintaining full control over network boundaries, DNS, and routing policies.   #370</p> <p>Agentic Retrieval   Adds intelligent, agent-driven retrieval orchestration that dynamically selects and combines information sources for more grounded and context-aware responses.   #359</p>"},{"location":"whatisnew/#september-2025","title":"September 2025","text":"<p>Release 2.1.0 - User Feedback Loop</p> <p>Introduces a mechanism for end-users to provide thumbs-up or thumbs-down feedback on assistant responses, storing these signals alongside conversation history to continuously improve response quality.</p> <ul> <li>How to configure it: User Feedback Configuration</li> <li>Demo video:</li> </ul>"}]}