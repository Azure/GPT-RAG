{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#gpt-rag-solution-accelerator","title":"GPT-RAG Solution Accelerator","text":""},{"location":"#overview","title":"Overview","text":"<p>GPT-RAG is a powerful, enterprise-ready accelerator that transforms how organizations build Retrieval-Augmented Generation (RAG) solutions on Azure. By leveraging Azure OpenAI, AI Search, and AI Foundry, it delivers a secure, modular foundation for creating intelligent conversational assistants and data-driven applications. View the source code on GitHub.</p> <p></p> <p>Built from the ground up with Zero-Trust security principles and Infrastructure as Code (IaC), GPT-RAG accelerates your journey to production-ready AI solutions. Whether you're working with text, images, or voice, this comprehensive platform combines enterprise-grade security, intelligent orchestration, and multimodal capabilities to deliver exceptional user experiences faster than ever.</p>"},{"location":"#core-services","title":"Core Services","text":"Services Description Orchestrator Manages multi-agent workflows and retrieves context using Semantic Kernel and Azure AI. Web UI User interface for chat interactions, supports streaming and custom themes. Data Ingestion Extracts, chunks, and indexes enterprise data for optimized retrieval. MCP Server Implements the Model Context Protocol for tool hosting and business logic integration."},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions from the community! Check our Contribution Guidelines for CLA, code of conduct, and PR guidelines.</p>"},{"location":"architecture/","title":"Overview","text":""},{"location":"architecture/#architecture","title":"\ud83c\udfdb\ufe0f Architecture","text":"<p>Download Visio Diagram</p>"},{"location":"architecture/#key-capabilities","title":"Key Capabilities","text":"<ul> <li> <p>Enterprise-Grade Security   Zero-Trust architecture with private endpoints, Azure Key Vault integration, and comprehensive monitoring.</p> </li> <li> <p>Flexible &amp; Customizable   Modular design with customizable orchestration, multiple interface options, and bring-your-own-resources support.</p> </li> <li> <p>Multimodal Experience   Native support for text, images, and voice with SharePoint and Fabric connectors for seamless data integration.</p> </li> <li> <p>Production Ready   Enterprise-ready infrastructure with support for CI/CD pipelines and quality evaluation integration.</p> </li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>We appreciate contributions and suggestions for this project! Before contributing, you'll need to sign a Contributor License Agreement (CLA) to confirm that you have the rights to, and do, grant us permission to use your contribution. More details can be found at Microsoft CLA.</p> <p>This project adheres to the Microsoft Open Source Code of Conduct. For more information, please visit the Code of Conduct FAQ or contact opencode@microsoft.com with any questions or comments.</p> <p>Below, you'll find details on how our code update process works and instructions on how to contribute.</p>"},{"location":"contributing/#contribution-guidelines","title":"Contribution Guidelines","text":"<p>To maintain project quality, the following items will be considered during the PR review.</p> <p>Adhering to these best practices will streamline the review process.</p> <ul> <li> <p>Target the <code>develop</code> Branch: Always direct your pull request to the <code>develop</code> branch to ensure that changes are properly integrated into the project's development workflow.</p> </li> <li> <p>Keep Pull Requests Small: Aim to make your pull requests as focused and concise as possible. This makes it easier to review and ensures quicker integration into the codebase.</p> </li> <li> <p>Associate with Prioritized Issues: Ensure that each pull request is linked to a specific, prioritized issue in the project backlog. This helps maintain alignment with project goals and ensures that work is being done on tasks of the highest importance.</p> </li> <li> <p>Include Documentation: Every new feature or functionality must be accompanied by clear documentation explaining its purpose and configuration. This ensures others can use it independently in a self-service manner.</p> </li> <li> <p>Bugs and Documentation Corrections: Pull requests that address bugs or correct documentation do not need to be associated with prioritized issues. These can be submitted directly to maintain the quality and accuracy of the project.</p> </li> <li> <p>Multi-Repo Dependencies: If your pull request has dependencies on updates in other repositories, make sure to mention this in the pull request description. Additionally, create a corresponding pull request in the other repository to ensure synchronized updates across all related projects.</p> </li> </ul>"},{"location":"contributing/#code-update-workflow","title":"Code Update Workflow","text":"<p>We use a simplified version of the Fork and Branch Workflow alongside Git Flow for branching strategy. The <code>main</code> branch always contains deployment-ready code, while the <code>develop</code> branch serves as our integration branch.</p> <p>Contributors create feature branches from <code>develop</code> in their forks. Once changes are completed, they submit a pull request to the <code>develop</code> branch in the upstream repository. After review and approval, reviewers merge the changes into <code>develop</code>. Weekly, maintainers group these changes into a pull request from <code>develop</code> to <code>main</code> for final review and merging.</p>"},{"location":"contributing/#step-by-step-process-overview","title":"Step-by-Step Process Overview","text":"<p>This section outlines the contribution process, highlighting the key actions for both contributors and reviewers. The accompanying diagram visually represents the workflow.</p> <p></p>"},{"location":"contributing/#contributor","title":"Contributor","text":"<ol> <li>Fork the Repository: Create a copy of the original repository in your GitHub account.</li> <li>Clone Locally: Download the forked repository to your machine.</li> <li>Add Upstream: Link the original repository as \"upstream\" to keep your fork synced.</li> <li>Create a Feature Branch: Start a new branch for your changes.</li> <li>Commit and Push Changes: Implement your changes and push them to your GitHub fork.</li> <li>Open a Pull Request: Submit your changes for review. If approved, they\u2019ll be merged into the <code>develop</code> branch and later into <code>main</code> based on the project\u2019s release process.</li> <li>Keep Your Fork Updated: Regularly sync your fork with the original repository to stay current.</li> </ol>"},{"location":"contributing/#contributors-step-by-step-guide","title":"Contributor's Step-by-Step Guide","text":"<p>Here\u2019s an example of how to implement a feature called <code>conversation-metadata</code> in the <code>gpt-rag-orchestrator</code> repository. The process is similar for other repositories, such as <code>gpt-rag-ingestion</code>.</p> <ol> <li>Create a Fork by clicking the Fork button on the repository page on GitHub. Be sure to include all branches.</li> </ol> <p><code>https://github.com/placerda/gpt-rag-orchestrator.git</code></p> <ol> <li>Clone Your Fork Locally using the standard clone command.</li> </ol> <p><code>git clone https://github.com/placerda/gpt-rag-orchestrator.git</code></p> <ol> <li>Set Upstream Remote: Link the original repository as \"upstream\" for future use.</li> </ol> <p><code>git remote add upstream git@github.com:Azure/gpt-rag-orchestrator.git</code></p> <ol> <li>Create a Feature Branch in your forked repository.</li> </ol> <p><code>git checkout -b feature/conversation-metadata</code></p> <ol> <li>Make Changes Locally: Modify the code in your local clone. Commit your changes and push them to your fork on GitHub.</li> </ol> <p><code>bash    git add .    git commit -m 'Implemented conversation metadata'    git push origin feature/conversation-metadata</code></p> <ol> <li>Create a Pull Request: Go to your fork on GitHub and click \"Pull Request.\" This request, aimed at the <code>develop</code> branch, will be reviewed and potentially merged by the repository maintainers.</li> </ol> <p>Done! Now, wait for the review and approval of your pull request. Changes may be requested.</p>"},{"location":"contributing/#keeping-your-fork-updated","title":"Keeping Your Fork Updated","text":"<p>It\u2019s recommended that you update your local clone after your pull request is approved. Follow these steps:</p> <pre><code>git pull upstream main\ngit push origin main\ngit pull upstream develop\ngit push origin develop\n</code></pre>"},{"location":"contributing/#cleaning-your-repo-after-pr-acceptance","title":"Cleaning Your Repo After PR Acceptance","text":"<p>Once your changes are merged, you can delete the feature branch from your local clone using these commands:</p> <pre><code>git switch develop\ngit branch -d feature/conversation-metadata\ngit push --delete origin feature/conversation-metadata\n</code></pre>"},{"location":"deploy/","title":"\ud83d\ude80 Deployment Guide","text":"<p>Choose your preferred deployment method based on project requirements and environment constraints.</p> <p>Note: You can change parameter values in <code>main.parameters.json</code> or set them with <code>azd env set</code> before running <code>azd provision</code>. This applies only to parameters that support environment variable substitution.</p>"},{"location":"deploy/#prerequisites","title":"Prerequisites","text":"<p>Required Permissions:</p> <ul> <li>Azure subscription with Contributor and User Access Admin roles</li> <li>Agreement to Responsible AI terms for Azure AI Services</li> </ul> <p>Required Tools:</p> <ul> <li>Azure Developer CLI</li> <li>PowerShell 7+ (Windows only)</li> <li>Git</li> <li>Python 3.12</li> </ul>"},{"location":"deploy/#quick-start-basic-deployment","title":"Quick Start - Basic Deployment","text":"<p>Quick setup for demos without network isolation.</p> <pre><code>azd init -t azure/gpt-rag\nazd provision\n</code></pre> <p>Demo video:</p>"},{"location":"deploy/#zero-trust-deployment","title":"Zero Trust Deployment","text":"<p>For deployments that require network isolation.</p>"},{"location":"deploy/#before-provisioning","title":"Before Provisioning","text":"<p>Enable network isolation in your environment:</p> <pre><code>azd env set NETWORK_ISOLATION true\n</code></pre>"},{"location":"deploy/#provision-infrastructure","title":"Provision Infrastructure","text":"<pre><code>azd provision\n</code></pre>"},{"location":"deploy/#post-provision-configuration","title":"Post-Provision Configuration","text":"<p>The Bicep template provisions a Jumpbox VM by default. You can connect to it to perform the post-provision steps, deploy services, and run tests.</p> <p>Option A \u2013 Using the deployed Jumpbox VM</p> <ol> <li>Connect via Azure Bastion.</li> <li>Open a terminal in the VM and run:</li> </ol> <p><code>cd C:\\github\\gpt-rag    .\\scripts\\postProvision.ps1</code></p> <p>Option B \u2013 From your local machine (must have VNet access)</p> <ol> <li>From the <code>gpt-rag</code> directory, run:</li> </ol> <p><code>.\\scripts\\postProvision.ps1</code></p> <p>or (Bash)</p> <p><code>.\\scripts\\postProvision.sh</code></p> <ol> <li>If you have re-initialized or cloned the repo again, refresh your <code>azd</code> environment so it points to the existing deployment:</li> </ol> <p><code>azd init -t azure/gpt-rag    azd env refresh</code></p> <ol> <li>When prompted, select the same Subscription, Resource Group, and Location as the original provisioning so <code>azd</code> correctly links to your environment.</li> </ol>"},{"location":"deploy/#deploy-gpt-rag-services","title":"Deploy GPT-RAG Services","text":"<p>Once the GPT-RAG infrastructure is provisioned, you can deploy the services.</p> <p>To deploy all services at once, navigate to the <code>gpt-rag</code> directory (with azd environment configured) and run:</p> <pre><code>azd deploy\n</code></pre> <p>This command deploys each service in sequence.</p> <p>If you prefer to deploy a single service\u2014for example, when updating only that service\u2014navigate to the corresponding service repository and follow the instructions in its \"How to Deploy\" section.</p>"},{"location":"deploy/#permissions","title":"Permissions","text":"<p>AI Foundry Role and AI Search Assignments</p> Resource Role Assignee Description GenAI App Search Service Search Index Data Reader AI Foundry Project Read index data GenAI App Search Service Search Service Contributor AI Foundry Project Create AI search connection GenAI App Storage Account Storage Blob Data Reader AI Foundry Account Read blob data GenAI App Storage Account Storage Blob Data Reader Search Service Read blob data for search integration AI Foundry Storage Account Storage Blob Data Contributor AI Foundry Project Enable agent to store/retrieve blob artifacts in customer storage AI Foundry Storage Account Containers Storage Blob Data Owner (workspace) AI Foundry Project Scoped owner access to workspace containers for session-specific data AI Foundry Cosmos DB Account Cosmos DB Operator AI Foundry Project Control-plane operations for enterprise memory database (threads) AI Foundry Cosmos DB Containers Cosmos DB Built-in Data Contributor AI Foundry Project Read/write conversation threads within enterprise memory containers AI Foundry Search Service Search Service Contributor AI Foundry Project Create/update indexes for vector search workflows AI Foundry Search Service Search Index Data Contributor AI Foundry Project Read/write index data for embedding-based queries <p>Container App Role Assignments</p> Resource Role Assignee Description GenAI App Configuration Store App Configuration Data Reader ContainerApp: orchestrator Read configuration data GenAI App Configuration Store App Configuration Data Reader ContainerApp: frontend Read configuration data GenAI App Configuration Store App Configuration Data Reader ContainerApp: dataingest Read configuration data GenAI App Configuration Store App Configuration Data Reader ContainerApp: mcp Read configuration data GenAI App Container Registry AcrPull ContainerApp: mcp Pull container images GenAI App Container Registry AcrPull ContainerApp: orchestrator Pull container images GenAI App Container Registry AcrPull ContainerApp: frontend Pull container images GenAI App Container Registry AcrPull ContainerApp: dataingest Pull container images GenAI App Key Vault Key Vault Secrets User ContainerApp: orchestrator Read secrets GenAI App Key Vault Key Vault Secrets User ContainerApp: frontend Read secrets GenAI App Key Vault Key Vault Secrets User ContainerApp: dataingest Read secrets GenAI App Key Vault Key Vault Secrets User ContainerApp: mcp Read secrets GenAI App Search Service Search Index Data Reader ContainerApp: orchestrator Read index data GenAI App Search Service Search Index Data Contributor ContainerApp: dataingest Read/write index data GenAI App Search Service Search Index Data Contributor ContainerApp: mcp Read/write index data GenAI App Storage Account Storage Blob Data Reader ContainerApp: orchestrator Read blob data GenAI App Storage Account Storage Blob Data Reader ContainerApp: frontend Read blob data GenAI App Storage Account Storage Blob Data Contributor ContainerApp: dataingest Read/write blob data GenAI App Storage Account Storage Blob Data Contributor ContainerApp: mcp Read/write blob data GenAI App Storage Account Storage Queue Data Contributor ContainerApp: mcp Read/write storage queue data GenAI App Cosmos DB Cosmos DB Built-in Data Contributor ContainerApp: orchestrator Read/write Cosmos DB data AI Foundry Account Cognitive Services User ContainerApp: orchestrator Access Cognitive Services operations AI Foundry Account Cognitive Services User ContainerApp: dataingest Access Cognitive Services operations AI Foundry Account Cognitive Services OpenAI User ContainerApp: orchestrator Use OpenAI APIs AI Foundry Account Cognitive Services OpenAI User ContainerApp: dataingest Use OpenAI APIs AI Foundry Account Cognitive Services User ContainerApp: mcp Access Cognitive Services AI Foundry Account Cognitive Services OpenAI User ContainerApp: mcp Use OpenAI APIs <p>Executor Role Assignments</p> Resource Role Assignee Description GenAI App Configuration Store App Configuration Data Owner Executor Full control over configuration settings GenAI App Container Registry AcrPush Executor Push container images GenAI App Key Vault Key Vault Contributor Executor Manage Key Vault settings GenAI App Key Vault Key Vault Secrets Officer Executor Create Key Vault secrets GenAI App Search Service Search Service Contributor Executor Create/update search service elements GenAI App Search Service Search Index Data Contributor Executor Read/write search index data GenAI App Storage Account Storage Blob Data Contributor Executor Read/write blob data GenAI App Cosmos DB Cosmos DB Built-in Data Contributor Executor Read/write Cosmos DB data AI Foundry Project Azure AI Project Manager Executor Manage AI Foundry projects and assign roles <p>Jumpbox VM Role Assignments</p> Resource Role Assignee Description GenAI App Container Apps Container Apps Contributor Jumpbox VM Full control over Container Apps (deploy/manage apps) Azure Managed Identity Managed Identity Operator Jumpbox VM Assign and manage user-assigned managed identities GenAI App Container Registry Container Registry Repository Writer Jumpbox VM Write to specific repositories GenAI App Container Registry Container Registry Tasks Contributor Jumpbox VM Manage ACR tasks GenAI App Container Registry Container Registry Data Access Configuration Administrator Jumpbox VM Manage data access configuration for ACR GenAI App Container Registry AcrPush Jumpbox VM Push container images GenAI App Configuration Store App Configuration Data Owner Jumpbox VM Full control over configuration settings GenAI App Key Vault Key Vault Contributor Jumpbox VM Manage Key Vault settings GenAI App Key Vault Key Vault Secrets Officer Jumpbox VM Create Key Vault secrets GenAI App Search Service Search Service Contributor Jumpbox VM Create/update search service elements GenAI App Search Service Search Index Data Contributor Jumpbox VM Read/write search index data GenAI App Storage Account Storage Blob Data Contributor Jumpbox VM Read/write blob data AI Foundry Account Azure AI Project Manager Jumpbox VM Manage AI Foundry projects and assign roles AI Foundry Account Cognitive Services Contributor Jumpbox VM Manage Cognitive Services resources GenAI App Cosmos DB Cosmos DB Built-in Data Contributor Jumpbox VM Read/write Cosmos DB data"},{"location":"orchestrator-visual-guide/","title":"Orchestrator visual guide","text":""},{"location":"orchestrator-visual-guide/#orchestrator-start-your-code-reading-with-visuals","title":"Orchestrator: Start Your Code Reading with Visuals","text":"<p>A picture is worth a thousand words. Yet many engineers write another thousand words instead of drawing a single useful diagram. Let\u2019s reverse this evolution \u2014 with visuals.</p> <p>Starting with diagrams \u2014 with a bit of simplification and abstraction \u2014 can significantly accelerate the comprehension of complex codebases. This is especially true when the data flow spans multiple execution environments (local machine (or VM on cloud), remote AI Foundry, Azure cloud resources), where the initial orientation can otherwise be challenging.</p>"},{"location":"orchestrator-visual-guide/#why-this-article-exists","title":"Why This Article Exists","text":"<p>When I started reading the code, I struggled:</p> <ul> <li>Where is the entry point?</li> <li>What calls what?</li> <li>What runs locally and what in the cloud?</li> <li>What is the big picture (helicopter view)?</li> <li>Which design patterns are applied?</li> <li>What is the role of the Orchestrator in the data flow?</li> </ul> <p>If you have ever felt dazed and confused by a codebase with many layers of abstraction, this is for you. If you prefer talking for hours about a diagram instead of drawing it, just leave.</p>"},{"location":"orchestrator-visual-guide/#target-audience","title":"Target Audience","text":"<p>Folks with an engineering mindset who want to understand before modifying.</p>"},{"location":"orchestrator-visual-guide/#hardware-recommendation","title":"Hardware Recommendation","text":"<p>Use a large monitor (32-inch or larger). Diagrams require space.</p> <p>Note: Each diagram is available in multiple formats (<code>.png</code>, <code>.jpg</code>, <code>.svg</code>). While SVG is technically the optimal and resolution-independent format, some operating systems and PDF export workflows do not reliably render SVG. To ensure accessibility and consistent viewing experience across different environments, alternative formats are provided.</p>"},{"location":"orchestrator-visual-guide/#start-with-the-glossary","title":"Start With the Glossary","text":"<p>The glossary is a shared language. Without clear and standardized terminology, people cannot meaningfully discuss ideas \u2014 they end up talking past each other. Shared terms are the foundation of shared understanding.</p> Term Definition Ask What the user says in natural language. It is the raw user message before any system processing. Query The Ask transformed into a form suitable for retrieval (for example, converted to an embedding vector). The embedding vector is used to retrieve grounding document chunks from a vector database. Note: The Query is not part of the Prompt. Note: In practice, Ask and Query are often used interchangeably. Prompt The final constructed input sent to the language model. It may include the user\u2019s Ask, retrieved document chunks, dialogue history, and system instructions. Request The HTTPS API call sent to the model endpoint to generate a Response. Response The output returned by the model after processing a Request. Message A single user, assistant, or system message in a Conversation. It can be an Ask, a Response, or a system/instruction message that may be included when constructing a Prompt. Turn A pair of Ask + Response. Interaction Another word for Turn. One full cycle of Ask \u2192 Response. Conversation A sequence of Interactions over time (many Turns), with the history persisted and reused as context. Dialogue The communication pattern of exchanging messages. A Conversation is an instance of a Dialogue sustained over time. Thread A platform-specific (AI Foundry) object that persists the Conversation History, identified by a thread ID. ---"},{"location":"orchestrator-visual-guide/#conversation-is-a-sequence-of-turns-interactions","title":"Conversation is a Sequence of Turns (Interactions)","text":"<p>Each user Ask and system Response adds one turn to the conversation.</p> <pre><code>Conversation\n  \u251c\u2500\u2500 Turn #1\n  \u2502      Ask\n  \u2502      Response\n  \u251c\u2500\u2500 Turn #2\n  \u2502      Ask\n  \u2502      Response\n  \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"orchestrator-visual-guide/#retrieving-grounding-chunks","title":"Retrieving Grounding Chunks","text":"<p>Grounding Chunks are critical because they anchor the model\u2019s answer in factual, domain-correct information instead of relying on the model\u2019s general knowledge or guesswork. Note: Retrieval is based solely on the Ask. No other parts of the Prompt are used. The only input used for retrieval is the Ask.</p> <pre><code>-----------------------------\nAsk (user text)\n   |\n   | The Ask is converted into an embedding vector.\n   |\n   v\nQuery (the embedding vector used for retrieval)\n   |\n   | retrieval from a vector database\n   |\n   v\nGrounding Chunks\n-----------------------------\n</code></pre>"},{"location":"orchestrator-visual-guide/#constructing-and-processing-the-prompt","title":"Constructing and Processing the Prompt","text":"<p>The Prompt is fed into the LLM model, which in turn generates the Response.</p> <pre><code>-----------------------------\nPrompt = System prompt\n       + Conversation History\n       + Ask\n       + Grounding Chunks\n       + Instructions\n       + Formatting Rules\n-----------------------------\n   |\n   | LLM takes Prompt\n   |\n   v\nResponse (LLM output)\n   |\n   | AI Foundry maintains Conversation History\n   | inside Thread objects\n   |\n   v\nConversation grows by one Turn (Ask + Response)\n</code></pre>"},{"location":"orchestrator-visual-guide/#example-of-a-real-prompt","title":"Example of a Real Prompt","text":"<p>Note: Grounding chunks are not part of the Conversation History. This can feel counter-intuitive, because they appear in the prompt alongside the user message, but they are inserted only at runtime to support retrieval. They are not stored or carried forward as part of the dialogue context (Conversation History).</p> <pre><code>-----------------------------------------------------------\nSYSTEM:\nYou are a helpful customer support assistant.\n\nCONVERSATION HISTORY:\n\"\"\"\nUSER ASK: How do I know my account is active?\nRESPONSE: You can sign in.\nUSER ASK: Do you notify me before expiration date?\nRESPONSE: Yes, we will text you.\n\"\"\"\n\nUSER ASK:\nHow do I renew my business account?\n\nRETRIEVED CONTEXT:\nDocument: Renewal Policy Guide\nTo renew the business account, the user must log in, navigate to 'Billing', select 'Account Renewal', and submit updated documents.\n\nINSTRUCTIONS:\nAnswer using the context above. If the answer is not in the context, say you don\u2019t know.\n\nFORMATTING RULES:\nRespond in Markdown.\n-----------------------------------------------------------\n</code></pre>"},{"location":"orchestrator-visual-guide/#orchestrator-core-responsibilities-collaboration","title":"Orchestrator: Core Responsibilities &amp; Collaboration","text":"<p>The entry point is in src/main.py: <code>orchestrator_endpoint()</code>. In what follows we will consider the Single-Agent RAG Strategy.</p> <pre><code>@app.post(\n    \"/orchestrator\",\n    dependencies=[Depends(validate_auth)], \n    summary=\"Ask orchestrator a question\",\n    response_description=\"Returns the orchestrator\u2019s response in real time, streamed via SSE.\",\n    responses=ORCHESTRATOR_RESPONSES\n)\nasync def orchestrator_endpoint(\n    body: OrchestratorRequest,\n    x_api_key: Optional[str] = Header(None, alias=\"X-API-KEY\"),\n    dapr_api_token: Optional[str] = Header(None, alias=\"dapr-api-token\"),\n):\n</code></pre>"},{"location":"orchestrator-visual-guide/#essential-tasks-of-the-orchestrator","title":"Essential Tasks of the Orchestrator","text":"<p>The <code>Orchestrator</code> class serves as the conversation state manager and strategy coordinator. Its core responsibilities are:</p> <ol> <li>Conversation Lifecycle Management: Creates, loads, and persists conversation documents in the CosmosDB.</li> <li>Strategy Delegation: Routes processing to appropriate agent strategies via factory pattern (<code>AgentStrategyFactory</code>).</li> <li>State Coordination: Ensures conversation state is properly synchronized between database and strategy</li> <li>Response Streaming: Coordinates real-time response delivery while maintaining state consistency</li> </ol>"},{"location":"orchestrator-visual-guide/#collaboration-pattern","title":"Collaboration Pattern","text":"<pre><code>------------------------------------------------------------------\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Orchestrator  \u2502\u25c4\u2500\u2500\u25ba\u2502   CosmosDBClient \u2502    \u2502 AgentStrategy   \u2502\n\u2502                 \u2502    \u2502                  \u2502    \u2502   Factory       \u2502\n\u2502 - Load/Save     \u2502    \u2502 - get_document() \u2502    \u2502                 \u2502\n\u2502 - Stream coord. \u2502    \u2502 - update_doc()   \u2502    \u2502 - get_strategy()\u2502\n\u2502 - State mgmt.   \u2502    \u2502 - create_doc()   \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n         \u2502                                               \u2502\n         \u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2510\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502        BaseAgentStrategy          \u2502\n                        \u2502                                   \u2502\n                        \u2502 - initiate_agent_flow()           \u2502\n                        \u2502 - conversation (property)         \u2502\n                        \u2502 - user_context (property)         \u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n------------------------------------------------------------------\n</code></pre>"},{"location":"orchestrator-visual-guide/#strategy-setup-streaming-response-lifecycle","title":"Strategy Setup + Streaming Response Lifecycle","text":"<p>Note the (read and update) points of conversation persistency maintenance (in green).</p> <p>\ud83d\udfe6 SVG \u00b7 \ud83d\udfe8 PNG \u00b7 \ud83d\udfe5 JPG</p> <p></p>"},{"location":"orchestrator-visual-guide/#singleagentragstrategy-remotely-controls-objects-in-the-ai-foundry","title":"<code>SingleAgentRAGStrategy</code> remotely controls objects in the AI Foundry","text":"<p>Essentials: - The entry point for the selected Strategy is the method <code>agentic_strategy.initiate_agent_flow()</code>.</p> <pre><code># orchestrator.py\n# line 76\n      # 3) Stream all chunks from the strategy\n      try:\n          yield f\"{self.conversation_id} \"\n          async for chunk in self.agentic_strategy.initiate_agent_flow(ask):\n              yield chunk\n      finally:\n          # 4) Persist whatever the strategy has updated (e.g. thread_id)\n          await self.database_client.update_document(self.database_container, self.agentic_strategy.conversation)\n</code></pre> <ul> <li>Note that the strategy object incarnated from the <code>SingleAgentRAGStrategy</code> class is running locally (or on a VM in the cloud) and readily controls the sequence of activities behind the AI Foundry wall.</li> <li>To that end, the strategy object is using the <code>project_client</code> object as a local proxy (which you may think of as a remote TV control).</li> <li>The strategy object does not handle grounding or LLM calls; these are delegated to the AI Foundry.</li> <li>The entire RAG pattern is exercised inside of the AI Foundry.</li> </ul> <p></p> <p>The strategy object <code>SingleAgentRAGStrategy</code> - creates a new agent by specifying instructions and a toolbox, - retrieves the <code>Thread</code> object based on the thread_id which was retrieved from the CosmosDB, - creates a new message from the user's Ask and attaches it to the Thread object, - finally calls the project_client.agents.runs.stream() which triggers the RAG pipeline inside of the AI Foundry realm.</p> <p>Note that <code>Thread</code> objects keep the entire history of conversations. There are two levels of history persistence - one in CosmosDB, - another one in Thread objects.</p> <p><code>Orchestrator</code> keeps a history (using CosmosDB) identified by <code>conversation_id</code> which arrives in the HTTP Request payload. One of the attributes stored in the CosmosDB is <code>thread_id</code> which points to the <code>Thread</code> object which resides inside of the AI Foundry. AI Foundry maintains its own internal persistency in the Thread objects.</p> <p>The strategy object triggers the RAG pipeline execution inside of AI Foundry with the proxy <code>project_client</code>:</p> <pre><code>project_client.agents.runs.stream(\n    thread_id=thread.id,\n    agent_id=agent.id,\n    ...\n)\n</code></pre> <p>Here is what it does: - Takes the user's Ask. - Queries your Azure AI Search index using the <code>AzureAISearchTool</code>. - Retrieves relevant document Chunks. - Creates the Prompt (see above for an example). - Previously retrieved Chunks are included into the Prompt to ground the Response. - Prompt is fed into LLM which generates Response. - The Response is enhanced by citations and references to the grounding documents.</p> <p>\ud83d\udfe6 SVG \u00b7 \ud83d\udfe8 PNG \u00b7 \ud83d\udfe5 JPG</p> <p></p>"},{"location":"orchestrator-visual-guide/#detailed-singleagentragstrategyinitiate_agent_flow-for-gurus","title":"Detailed <code>SingleAgentRAGStrategy.initiate_agent_flow()</code> for Gurus","text":"<p>The sequence diagram above is intended to illustrate the core concepts and design patterns present in the codebase. The visualization deliberately simplifies reality through abstraction and by omitting less relevant details.</p> <p>In contrast, the following diagram remains closely aligned with the actual implementation. I acknowledge the argument that directly reading the code may, in some cases, be more effective. However, if you wish to uncover the inner workings behind the AI Foundry orchestration, I recommend using a large display and taking the time to explore the diagram in depth.</p> <p>I should note that the detailed diagram below is the outcome of several iterative discussions with ChatGPT and GitHub Copilot.</p> <p>\ud83d\udfe6 SVG \u00b7 \ud83d\udfe8 PNG</p> <p></p>"},{"location":"orchestrator-visual-guide/#ai-foundry-whats-really-happening-behind-the-scenes","title":"AI Foundry: What\u2019s Really Happening Behind the Scenes","text":"<p>The purpose of the following diagram is to reveal the internal workings of the AI Foundry at a deeper level, including its collaboration with Azure AI Search and Bing Search. The entry point for this process is the <code>project_client.agents.runs.stream()</code> method.</p> <p>The detailed diagram is a result of several iterative discussions with ChatGPT and GitHub Copilot.</p> <p>\ud83d\udfe6 SVG \u00b7 \ud83d\udfe8 PNG</p> <p></p>"},{"location":"orchestrator-visual-guide/#how-to-read-these-diagrams","title":"How to Read These Diagrams","text":"<ul> <li>Left \u2192 Right = Components</li> <li>Top \u2192 Bottom = Time</li> <li>Solid Arrows = Calls</li> <li>Dashed Arrows = Returns / Streams</li> <li>Background Colors = Logical Stages</li> </ul> <p>Read the diagram before reading the code.</p>"},{"location":"orchestrator-visual-guide/#link-to-the-repository","title":"Link to the Repository","text":"<p>Repository: https://github.com/Azure/gpt-rag-orchestrator</p> Concept File Notes Orchestrator entry <code>main.py</code> FastAPI route + request handling Orchestrator implementation <code>orchestration/orchestrator.py</code> Maintains Conversation History + runs streaming pipeline Strategy factory <code>strategies/agent_strategy_factory.py</code> Selects the execution strategy Single-Agent RAG Strategy <code>strategies/single_agent_rag_strategy.py</code> Implements flow to Azure AI Foundry"},{"location":"userfeedback/","title":"User Feedback Configuration","text":"<p>GPT-RAG includes a User Feedback Loop feature that lets users evaluate assistant responses through the UI. Feedback is sent to the backend, processed by the orchestrator, and stored in Cosmos DB for analysis and continuous improvement.</p> <p> User feedback stored in Cosmos DB</p> <p>By default, basic feedback (thumbs up/down) is enabled, while detailed ratings (star rating and comments) are disabled. Administrators control these options through Azure App Configuration.</p>"},{"location":"userfeedback/#feedback-types","title":"Feedback Types","text":"<p>When enabled, users can provide star ratings and text comments for richer feedback that captures both satisfaction and reasoning.</p> <p> User providing rating and comment feedback</p>"},{"location":"userfeedback/#configuration-settings","title":"Configuration Settings","text":"<p>The behavior of the feedback loop is controlled by key-values in Azure App Configuration:</p> <ul> <li>ENABLE_USER_FEEDBACK \u2192 Default: <code>true</code>   Controls whether the feedback feature is available at all.</li> </ul> <p> Key to enable or disable user feedback globally</p> <ul> <li>USER_FEEDBACK_RATING \u2192 Default: <code>false</code>   Controls whether users can provide detailed feedback with ratings and comments.</li> </ul> <p> Key to enable or disable detailed rating feedback</p>"},{"location":"userfeedback/#default-values","title":"Default Values","text":"<ul> <li><code>ENABLE_USER_FEEDBACK = true</code></li> <li><code>USER_FEEDBACK_RATING = false</code></li> </ul> <p>This means feedback is collected by default, but star ratings and comments must be explicitly enabled by setting <code>USER_FEEDBACK_RATING</code> to <code>true</code>.</p>"},{"location":"whatisnew/","title":"What's New","text":"<p>\ud83d\udccc Check out what's coming next  (Azure org only)</p>"},{"location":"whatisnew/#october-2025","title":"October 2025","text":"<p>Release 2.2.0 - Agentic Retrieval and Network Flexibility</p> <p>This release introduces major enhancements to support more flexible and enterprise-ready deployments.</p> <p>Bring Your Own VNet   Enables organizations to deploy GPT-RAG within their existing virtual network, maintaining full control over network boundaries, DNS, and routing policies.   #370</p> <p>Agentic Retrieval   Adds intelligent, agent-driven retrieval orchestration that dynamically selects and combines information sources for more grounded and context-aware responses.   #359</p>"},{"location":"whatisnew/#september-2025","title":"September 2025","text":"<p>Release 2.1.0 - User Feedback Loop</p> <p>Introduces a mechanism for end-users to provide thumbs-up or thumbs-down feedback on assistant responses, storing these signals alongside conversation history to continuously improve response quality.</p> <ul> <li>How to configure it: User Feedback Configuration</li> <li>Demo video:</li> </ul>"}]}